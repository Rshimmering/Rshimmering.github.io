<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业） | Rshimmer</title><meta name="keywords" content="Python,数据挖掘,逻辑回归,决策树,支持向量机,XGBoost,GBM"><meta name="author" content="Rshimmer"><meta name="copyright" content="Rshimmer"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#F0E68C"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业）"><meta name="application-name" content="Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业）"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#F0E68C"><meta property="og:type" content="article"><meta property="og:title" content="Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业）"><meta property="og:url" content="https://rshimmering.github.io/posts/fd7a19d1.html"><meta property="og:site_name" content="Rshimmer"><meta property="og:description" content="赛题背景：作为专业投资者，研究一家上市公司的财务数据是否稳健，需要考虑相关的诸多因素．面对上市公司多年的财务数据报告，投资者可通过数据挖掘，筛选数据指标进行跟踪分析和研究，识别真伪，避免投资踩雷． 要求： (1) 根据各行业的上市公司所提供的财务数据，确定出各行业与财务数据造假相关的数据指标，并分"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://rshimmering.github.io/pageimg/wallhaven-m917o9.jpg"><meta property="article:author" content="Rshimmer"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://rshimmering.github.io/pageimg/wallhaven-m917o9.jpg"><link rel="shortcut icon" href="/%F0%9F%8C%9B"><link rel="canonical" href="https://rshimmering.github.io/posts/fd7a19d1"><link rel="preconnect" href="//npm.elemecdn.com"><link rel="preconnect" href="//npm.onmicrosoft.cn"><meta name="google-site-verification" content="xxx"><meta name="baidu-site-verification" content="code-xxx"><meta name="msvalidate.01" content="xxx"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.14/dist/fancybox/fancybox.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/swiper/swiper.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG = { 
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":null},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#76B6EA","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业）",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2023-08-06 21:43:38",postMainColor:""}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#F0E68C')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#F0E68C')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/iconfont.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"><style>#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags:before{content:"\A";white-space:pre}#recent-posts>.recent-post-item>.recent-post-info>.article-meta-wrap>.tags>.article-meta__separator{display:none}</style><meta name="generator" content="Hexo 6.3.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="/img/t.jpg"><div class="loading-image-dot"></div><div id="loading-percentage">0%</div></div></div><script>if (GLOBAL_CONFIG.preloader.source == "2" || GLOBAL_CONFIG.preloader.source == "3") {
  const loadingPercentage = document.getElementById("loading-percentage");
  let loadingPercentageTimer = setInterval(function() {
    var progressBar = document.querySelector(".pace-progress");
    if (!progressBar) return
    var currentValue = progressBar.getAttribute("data-progress-text");
    if (currentValue !== loadingPercentage.textContent) {
      loadingPercentage.textContent = currentValue;
      if (currentValue === "100%") {
        clearInterval(loadingPercentageTimer);
      }
    }
  }, 100);
}

const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/progress_bar/progress_bar.css"><script async src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div id="web_box"><div id="web_container"><div id="menu-mask"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">Rshimmer</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span>🐼文章</span></a><ul class="menus_item_child" style="left:-79px"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size:.9em"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size:.9em"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size:.9em"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span>🥕我的</span></a><ul class="menus_item_child" style="left:-31px"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size:.9em"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size:.9em"></i><span> 百宝箱</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span>🌳关于</span></a><ul class="menus_item_child" style="left:-79px"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size:.9em"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size:.9em"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size:.9em"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole()"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png" target="_blank"><img class="post-qr-code-img" alt="wechat" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-weichat.png"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png" target="_blank"><img class="post-qr-code-img" alt="alipay" src="https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/qrcode-alipay.png"></a><div class="post-qr-code-desc">alipay</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"><span>最新评论</span></span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">音乐</div><span class="author-content-item-title">灵魂的碰撞💥</span></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/02/"><span class="card-archive-list-date">二月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">一月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">十月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">九月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">八月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">3</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">七月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">7</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/06/"><span class="card-archive-list-date">六月 2023</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">39</span><span>篇</span></div></a></li></ul></div><hr></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" onclick="anzhiyu.switchDarkMode()" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item on" id="consoleCommentBarrage" onclick="anzhiyu.switchCommentBarrage()" title="热评开关"><a class="commentBarrage"><i class="anzhiyufont anzhiyu-icon-message"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%81%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E9%A1%B9%E7%9B%AE/">数据分析、数据挖掘项目</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/Python/" tabindex="-1"> <span><i class="anzhiyufont anzhiyu-icon-hashtag"></i>Python</span></a><a class="article-meta__tags" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" tabindex="-1"> <span><i class="anzhiyufont anzhiyu-icon-hashtag"></i>数据挖掘</span></a><a class="article-meta__tags" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/" tabindex="-1"> <span><i class="anzhiyufont anzhiyu-icon-hashtag"></i>逻辑回归</span></a><a class="article-meta__tags" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/" tabindex="-1"> <span><i class="anzhiyufont anzhiyu-icon-hashtag"></i>决策树</span></a><a class="article-meta__tags" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" tabindex="-1"> <span><i class="anzhiyufont anzhiyu-icon-hashtag"></i>支持向量机</span></a><a class="article-meta__tags" href="/tags/XGBoost/" tabindex="-1"> <span><i class="anzhiyufont anzhiyu-icon-hashtag"></i>XGBoost</span></a><a class="article-meta__tags" href="/tags/GBM/" tabindex="-1"> <span><i class="anzhiyufont anzhiyu-icon-hashtag"></i>GBM</span></a></span></div></div><h1 class="post-title">Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-07T10:03:49.000Z" title="发表于 2023-06-07 18:03:49">2023-06-07</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-06T13:43:38.499Z" title="更新于 2023-08-06 21:43:38">2023-08-06</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-wordcount"><i class="anzhiyufont anzhiyu-icon-file-word post-meta-icon" title="文章字数"></i><span class="post-meta-label" title="文章字数">字数总计:</span><span class="word-count" title="文章字数">10.4k</span><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-clock post-meta-icon" title="阅读时长"></i><span class="post-meta-label" title="阅读时长">阅读时长:</span><span>58分钟</span></span><span class="post-meta-separator"> </span><span class="post-meta-position" title="作者IP属地为深圳"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>深圳</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="/pageimg/wallhaven-m917o9.jpg"></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>赛题背景：作为专业投资者，研究一家上市公司的财务数据是否稳健，需要考虑相关的诸多因素．面对上市公司多年的财务数据报告，投资者可通过数据挖掘，筛选数据指标进行跟踪分析和研究，识别真伪，避免投资踩雷．</p><p>要求：</p><p>(1) 根据各行业的上市公司所提供的财务数据，确定出各行业与财务数据造假相关的数据指标，并分析比较不同行业上市公司相关数据指标的异同．</p><p>(2) 根据制造业的各上市公司的财务数据，确定第 6 年财务数据造假的上市公司．</p><p>(3) 根据非制造业的上市公司的财务数据，确定第 6 年财务数据造假的上市公司．</p><p>意义：在大数据发展的时代下，通过人工智能、机器学习等智能化手段进行监控预测能够提高公司财务报告中的准确性、以及公司财务是否存在欺诈、隐瞒等行为，是提高公司信用风控的重要因素．</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">color = sns.color_palette()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> stats</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm, skew</span><br><span class="line"></span><br><span class="line">t1=pd.read_csv(<span class="string">&quot;制造业.csv&quot;</span>)</span><br><span class="line">t1_train=t1.drop(<span class="string">&quot;FLAG&quot;</span>,axis=<span class="number">1</span>)</span><br><span class="line">t1</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>TICKER_SYMBOL</th><th>ACT_PUBTIME</th><th>PUBLISH_DATE</th><th>END_DATE_REP</th><th>END_DATE</th><th>REPORT_TYPE</th><th>FISCAL_PERIOD</th><th>MERGED_FLAG</th><th>ACCOUTING_STANDARDS</th><th>CURRENCY_CD</th><th>...</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th><th>FLAG</th></tr></thead><tbody><tr><th>0</th><td>4019</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td></tr><tr><th>1</th><td>8166</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td></tr><tr><th>2</th><td>11737</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td></tr><tr><th>3</th><td>16479</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td></tr><tr><th>4</th><td>16842</td><td>4</td><td>4</td><td>3</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>0.0</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13965</th><td>4992204</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13966</th><td>4992858</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>0.000</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13967</th><td>4993201</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13968</th><td>4998808</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13969</th><td>4999709</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>2.6656</td><td>23.084</td><td>21.9179</td><td>0.6571</td><td>0.6256</td><td>33.6589</td><td>16.4249</td><td>0.3692</td><td>54.0618</td><td>NaN</td></tr></tbody></table><p>13970 rows × 363 columns</p></div><h1 id="数据预处理">数据预处理</h1><h2 id="计算缺失率-并降序排序">计算缺失率，并降序排序</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_data_na = (t1_train.isnull().<span class="built_in">sum</span>() / <span class="built_in">len</span>(t1_train) * <span class="number">100</span>).sort_values(ascending=<span class="literal">False</span>) </span><br><span class="line"></span><br><span class="line">missing_data = pd.DataFrame(&#123;<span class="string">&#x27;missing_data&#x27;</span> : all_data_na&#125;)</span><br><span class="line">missing_data </span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>missing_data</th></tr></thead><tbody><tr><th>ACCRUED_EXP</th><td>99.971367</td></tr><tr><th>N_INC_BORR_OTH_FI</th><td>99.806729</td></tr><tr><th>PERPETUAL_BOND_L</th><td>99.634932</td></tr><tr><th>PREFERRED_STOCK_L</th><td>99.606299</td></tr><tr><th>PREFERRED_STOCK_E</th><td>99.591983</td></tr><tr><th>...</th><td>...</td></tr><tr><th>T_COMPR_INCOME</th><td>0.000000</td></tr><tr><th>N_INCOME_ATTR_P</th><td>0.000000</td></tr><tr><th>FINAN_EXP</th><td>0.000000</td></tr><tr><th>ACT_PUBTIME</th><td>0.000000</td></tr><tr><th>TICKER_SYMBOL</th><td>0.000000</td></tr></tbody></table><p>362 rows × 1 columns</p></div><p>将缺失率用图表的方式展示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">f, ax = plt.subplots(figsize=(<span class="number">30</span>, <span class="number">15</span>))</span><br><span class="line">plt.xticks(rotation=<span class="string">&#x27;90&#x27;</span>)</span><br><span class="line">sns.barplot(x=all_data_na.index, y=all_data_na)   <span class="comment">#条形图</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Features&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Percent of missing values&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Percent missing data by feature&#x27;</span>, fontsize=<span class="number">15</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Text(0.5, 1.0, &#x27;Percent missing data by feature&#x27;)</span><br></pre></td></tr></table></figure><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/posts/fd7a19d1/output_6_1.png" title="output_6_1"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 统计缺失率大于80%的个数</span></span><br><span class="line">missing_data_count1 = all_data_na.index[all_data_na &gt; <span class="number">80</span>] </span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计缺失率小于20%的个数</span></span><br><span class="line">missing_data_count2 = all_data_na.index[all_data_na &lt; <span class="number">20</span>] </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(missing_data_count1.shape,missing_data_count2.shape)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(93,) (84,)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#缺失率&gt;80%的特征</span></span><br><span class="line">a=missing_data.values[:<span class="number">93</span>]</span><br><span class="line">x=pd.DataFrame(a, index = missing_data.index[:<span class="number">93</span>])</span><br><span class="line">x</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:left"><th></th><th>0</th></tr></thead><tbody><tr><th>ACCRUED_EXP</th><td>99.971367</td></tr><tr><th>N_INC_BORR_OTH_FI</th><td>99.806729</td></tr><tr><th>PERPETUAL_BOND_L</th><td>99.634932</td></tr><tr><th>PREFERRED_STOCK_L</th><td>99.606299</td></tr><tr><th>PREFERRED_STOCK_E</th><td>99.591983</td></tr><tr><th>...</th><td>...</td></tr><tr><th>OP_CL</th><td>81.338583</td></tr><tr><th>R_D</th><td>81.159628</td></tr><tr><th>N_CF_OPA_LIAB</th><td>80.952040</td></tr><tr><th>N_CF_NFA_LIAB</th><td>80.952040</td></tr><tr><th>OP_TL</th><td>80.916249</td></tr></tbody></table><p>93 rows × 1 columns</p></div><h2 id="删除80-以上的缺失率">删除80%以上的缺失率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t2=t1_train.drop(columns=x.index)</span><br><span class="line">t2</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>TICKER_SYMBOL</th><th>ACT_PUBTIME</th><th>PUBLISH_DATE</th><th>END_DATE_REP</th><th>END_DATE</th><th>REPORT_TYPE</th><th>FISCAL_PERIOD</th><th>MERGED_FLAG</th><th>ACCOUTING_STANDARDS</th><th>CURRENCY_CD</th><th>...</th><th>AP_TURNOVER</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th></tr></thead><tbody><tr><th>0</th><td>4019</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>1</th><td>8166</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>2</th><td>11737</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>3</th><td>16479</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>4</th><td>16842</td><td>4</td><td>4</td><td>3</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13965</th><td>4992204</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13966</th><td>4992858</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>0.000</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13967</th><td>4993201</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13968</th><td>4998808</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td><td>NaN</td></tr><tr><th>13969</th><td>4999709</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>10.6956</td><td>2.6656</td><td>23.084</td><td>21.9179</td><td>0.6571</td><td>0.6256</td><td>33.6589</td><td>16.4249</td><td>0.3692</td><td>54.0618</td></tr></tbody></table><p>13970 rows × 269 columns</p></div><h2 id="对缺失率20-到80-的数据填充中位数">对缺失率20%到80%的数据填充中位数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">b=missing_data.index[<span class="number">93</span>:<span class="number">278</span>]</span><br><span class="line"><span class="keyword">for</span> o <span class="keyword">in</span> b:</span><br><span class="line">    t2[o]=t2[o].fillna(t2[o].median())</span><br><span class="line">t2</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>TICKER_SYMBOL</th><th>ACT_PUBTIME</th><th>PUBLISH_DATE</th><th>END_DATE_REP</th><th>END_DATE</th><th>REPORT_TYPE</th><th>FISCAL_PERIOD</th><th>MERGED_FLAG</th><th>ACCOUTING_STANDARDS</th><th>CURRENCY_CD</th><th>...</th><th>AP_TURNOVER</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th></tr></thead><tbody><tr><th>0</th><td>4019</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>1</th><td>8166</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>2</th><td>11737</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>3</th><td>16479</td><td>3</td><td>3</td><td>2</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>4</th><td>16842</td><td>4</td><td>4</td><td>3</td><td>1</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13965</th><td>4992204</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>13966</th><td>4992858</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>0.0000</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>13967</th><td>4993201</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>13968</th><td>4998808</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>4.8617</td><td>1.0942</td><td>149.7293</td><td>4.1120</td><td>3.0696</td><td>2.7145</td><td>74.30515</td><td>87.75175</td><td>0.5354</td><td>8.49245</td></tr><tr><th>13969</th><td>4999709</td><td>7</td><td>7</td><td>7</td><td>6</td><td>A</td><td>12</td><td>1</td><td>CHAS_2007</td><td>CNY</td><td>...</td><td>10.6956</td><td>2.6656</td><td>23.0840</td><td>21.9179</td><td>0.6571</td><td>0.6256</td><td>33.65890</td><td>16.42490</td><td>0.3692</td><td>54.06180</td></tr></tbody></table><p>13970 rows × 269 columns</p></div><h2 id="对缺失率20-以下的数据使用knn填充">对缺失率20%以下的数据使用KNN填充</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">d=missing_data.index[<span class="number">278</span>:<span class="number">336</span>] <span class="comment">#列名</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> KNNImputer</span><br><span class="line"></span><br><span class="line">imputer = KNNImputer(n_neighbors=<span class="number">10</span>)</span><br><span class="line">t2[d] = imputer.fit_transform(t2[d])</span><br><span class="line"><span class="built_in">print</span>(t2.isnull().<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">TICKER_SYMBOL    0</span><br><span class="line">ACT_PUBTIME      0</span><br><span class="line">PUBLISH_DATE     0</span><br><span class="line">END_DATE_REP     0</span><br><span class="line">END_DATE         0</span><br><span class="line">                ..</span><br><span class="line">TFA_TURNOVER     0</span><br><span class="line">DAYS_AP          0</span><br><span class="line">DAYS_INVEN       0</span><br><span class="line">TA_TURNOVER      0</span><br><span class="line">AR_TURNOVER      0</span><br><span class="line">Length: 269, dtype: int64</span><br></pre></td></tr></table></figure><h2 id="删除与预测是否造假结果无关的特征因子">删除与预测是否造假结果无关的特征因子</h2><p>删除股票代码，实际披露时间，发布时间，报告截止日期，截止日期，报告类型，会计区间，合并标志：1-合并，2-母公司，会计准则，货币代码共 10 个与预测是否造假结果无关的特征因子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2=t2.drop([<span class="string">&quot;TICKER_SYMBOL&quot;</span>,<span class="string">&quot;ACT_PUBTIME&quot;</span>,<span class="string">&quot;PUBLISH_DATE&quot;</span>,<span class="string">&quot;END_DATE_REP&quot;</span>,<span class="string">&quot;END_DATE&quot;</span>,<span class="string">&quot;REPORT_TYPE&quot;</span>,<span class="string">&quot;FISCAL_PERIOD&quot;</span>,<span class="string">&quot;MERGED_FLAG&quot;</span>,<span class="string">&quot;ACCOUTING_STANDARDS&quot;</span>,<span class="string">&quot;CURRENCY_CD&quot;</span>],axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h2 id="查看是否还存在缺失值">查看是否还存在缺失值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t2.isna().<span class="built_in">any</span>().<span class="built_in">sum</span>()  </span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0</span><br></pre></td></tr></table></figure><h2 id="对数据进行标准化">对数据进行标准化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"></span><br><span class="line"><span class="comment">#标准化，返回值为标准化后的数据</span></span><br><span class="line">t4=pd.DataFrame(StandardScaler().fit_transform(t2),columns=t2.columns)</span><br><span class="line">t4</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>CASH_C_EQUIV</th><th>NOTES_RECEIV</th><th>AR</th><th>PREPAYMENT</th><th>INT_RECEIV</th><th>OTH_RECEIV</th><th>INVENTORIES</th><th>OTH_CA</th><th>T_CA</th><th>AVAIL_FOR_SALE_FA</th><th>...</th><th>AP_TURNOVER</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th></tr></thead><tbody><tr><th>0</th><td>-0.110544</td><td>-0.106696</td><td>-0.161667</td><td>-0.182694</td><td>-0.067294</td><td>-0.177580</td><td>-0.271929</td><td>-0.054680</td><td>-0.201905</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>1</th><td>-0.036496</td><td>1.088871</td><td>-0.182107</td><td>-0.052401</td><td>-0.085668</td><td>-0.026558</td><td>0.016419</td><td>-0.171927</td><td>0.060346</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>2</th><td>0.070766</td><td>-0.189223</td><td>0.057981</td><td>-0.140868</td><td>0.021829</td><td>-0.115114</td><td>-0.100801</td><td>0.073932</td><td>-0.023286</td><td>-0.110754</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>3</th><td>-0.039637</td><td>-0.205146</td><td>-0.184401</td><td>-0.159863</td><td>-0.062639</td><td>-0.060387</td><td>-0.197651</td><td>0.346521</td><td>-0.105029</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>4</th><td>-0.244743</td><td>-0.199970</td><td>-0.265148</td><td>-0.148300</td><td>-0.085668</td><td>-0.182752</td><td>-0.279125</td><td>-0.178592</td><td>-0.283117</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13965</th><td>-0.245654</td><td>-0.175257</td><td>-0.248184</td><td>-0.192613</td><td>-0.085668</td><td>-0.180662</td><td>-0.279316</td><td>-0.178050</td><td>-0.279115</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13966</th><td>-0.204023</td><td>-0.205182</td><td>-0.257308</td><td>-0.191965</td><td>-0.085668</td><td>-0.175087</td><td>-0.270255</td><td>-0.175323</td><td>-0.266459</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.063158</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13967</th><td>-0.227119</td><td>-0.204127</td><td>-0.201336</td><td>-0.164736</td><td>-0.085668</td><td>-0.164288</td><td>-0.183161</td><td>-0.162139</td><td>-0.237732</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13968</th><td>0.100220</td><td>-0.204577</td><td>-0.038156</td><td>-0.128786</td><td>-0.085668</td><td>-0.128173</td><td>0.075970</td><td>-0.152256</td><td>-0.019633</td><td>-0.068500</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13969</th><td>1.609554</td><td>0.222399</td><td>1.025478</td><td>0.436742</td><td>-0.085668</td><td>0.581671</td><td>0.691256</td><td>0.019537</td><td>1.080323</td><td>-0.087742</td><td>...</td><td>0.306581</td><td>2.042642</td><td>-0.058198</td><td>0.017576</td><td>-0.069761</td><td>-0.013200</td><td>-0.009263</td><td>-0.050238</td><td>-0.593860</td><td>-0.006262</td></tr></tbody></table><p>13970 rows × 259 columns</p></div><h1 id="划分数据集">划分数据集</h1><p>以前5年数据为训练集、验证集train,第6年为测试集test</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#以前5年数据为训练集、验证集train,第6年为测试集test</span></span><br><span class="line">train=t4.iloc[:<span class="number">11310</span>,:]</span><br><span class="line">test=t4.iloc[<span class="number">11310</span>:,:<span class="number">259</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train[<span class="string">&quot;FLAG&quot;</span>]=t1[<span class="string">&quot;FLAG&quot;</span>]</span><br><span class="line">train</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>CASH_C_EQUIV</th><th>NOTES_RECEIV</th><th>AR</th><th>PREPAYMENT</th><th>INT_RECEIV</th><th>OTH_RECEIV</th><th>INVENTORIES</th><th>OTH_CA</th><th>T_CA</th><th>AVAIL_FOR_SALE_FA</th><th>...</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th><th>FLAG</th></tr></thead><tbody><tr><th>0</th><td>-0.110544</td><td>-0.106696</td><td>-0.161667</td><td>-0.182694</td><td>-0.067294</td><td>-0.177580</td><td>-0.271929</td><td>-0.054680</td><td>-0.201905</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>1</th><td>-0.036496</td><td>1.088871</td><td>-0.182107</td><td>-0.052401</td><td>-0.085668</td><td>-0.026558</td><td>0.016419</td><td>-0.171927</td><td>0.060346</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>2</th><td>0.070766</td><td>-0.189223</td><td>0.057981</td><td>-0.140868</td><td>0.021829</td><td>-0.115114</td><td>-0.100801</td><td>0.073932</td><td>-0.023286</td><td>-0.110754</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>3</th><td>-0.039637</td><td>-0.205146</td><td>-0.184401</td><td>-0.159863</td><td>-0.062639</td><td>-0.060387</td><td>-0.197651</td><td>0.346521</td><td>-0.105029</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>4</th><td>-0.244743</td><td>-0.199970</td><td>-0.265148</td><td>-0.148300</td><td>-0.085668</td><td>-0.182752</td><td>-0.279125</td><td>-0.178592</td><td>-0.283117</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>11305</th><td>-0.248180</td><td>-0.177748</td><td>-0.244404</td><td>-0.195324</td><td>-0.085668</td><td>-0.182942</td><td>-0.277525</td><td>-0.177054</td><td>-0.279415</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>11306</th><td>-0.218672</td><td>-0.196336</td><td>-0.255531</td><td>-0.193333</td><td>-0.085668</td><td>-0.160477</td><td>-0.268560</td><td>-0.174560</td><td>-0.270623</td><td>-0.087742</td><td>...</td><td>-1.587291</td><td>2.125000</td><td>-0.031456</td><td>-0.041665</td><td>-0.012392</td><td>0.005011</td><td>2.477695</td><td>-1.585968</td><td>-0.054737</td><td>0.0</td></tr><tr><th>11307</th><td>-0.200565</td><td>-0.204200</td><td>-0.232985</td><td>-0.177734</td><td>-0.085668</td><td>-0.175507</td><td>-0.207126</td><td>-0.160690</td><td>-0.242246</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>11308</th><td>-0.101380</td><td>-0.197020</td><td>-0.049710</td><td>-0.100780</td><td>-0.085668</td><td>-0.178231</td><td>0.042636</td><td>-0.123428</td><td>-0.095392</td><td>-0.064501</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>11309</th><td>1.326097</td><td>0.141651</td><td>0.889289</td><td>0.170126</td><td>0.029234</td><td>0.515964</td><td>0.529339</td><td>0.024492</td><td>0.854325</td><td>2.263116</td><td>...</td><td>0.710450</td><td>-0.058365</td><td>0.016279</td><td>-0.071072</td><td>-0.013249</td><td>-0.009230</td><td>-0.050121</td><td>-0.719755</td><td>0.004747</td><td>0.0</td></tr></tbody></table><p>11310 rows × 260 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">train.to_excel(<span class="string">&quot;训练集、验证集.xlsx&quot;</span>)</span><br><span class="line">test.to_excel(<span class="string">&quot;测试集.xlsx&quot;</span>)</span><br></pre></td></tr></table></figure><h2 id="样本不均衡处理">样本不均衡处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train1=np.array(train.iloc[:<span class="number">11310</span>,:<span class="number">259</span>])</span><br><span class="line">y_train1 =train.FLAG.values</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所生成的样本类别分布，0和1样本比例9比1，属于类别不平衡数据</span></span><br><span class="line"><span class="built_in">print</span>(Counter(y_train1))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Counter(&#123;0.0: 11219, 1.0: 91&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># make data</span></span><br><span class="line">x = [<span class="number">11219</span>, <span class="number">91</span>]</span><br><span class="line">labels = [<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># plot</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.pie(x, radius=<span class="number">3</span>, center=(<span class="number">4</span>, <span class="number">4</span>),labels=labels, </span><br><span class="line">       wedgeprops=&#123;<span class="string">&quot;linewidth&quot;</span>: <span class="number">1</span>, <span class="string">&quot;edgecolor&quot;</span>: <span class="string">&quot;white&quot;</span>&#125;, autopct=<span class="string">&#x27;%.1f%%&#x27;</span>, frame=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">ax.<span class="built_in">set</span>(xlim=(<span class="number">0</span>, <span class="number">8</span>), xticks=np.arange(<span class="number">1</span>, <span class="number">8</span>),</span><br><span class="line">       ylim=(<span class="number">0</span>, <span class="number">8</span>), yticks=np.arange(<span class="number">1</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/posts/fd7a19d1/output_30_0.png" title="output_30_0"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> imblearn.over_sampling <span class="keyword">import</span> SMOTE</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成0和1比例为3比1的数据样本</span></span><br><span class="line">oversample = SMOTE(sampling_strategy=<span class="number">0.2</span>,random_state=<span class="number">42</span>)</span><br><span class="line">X_os, y_os = oversample.fit_resample(X_train1,y_train1)</span><br><span class="line"><span class="built_in">print</span>(Counter(y_os))</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Counter(&#123;0.0: 11219, 1.0: 2243&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_os.shape</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(13462, 259)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">a1 = pd.DataFrame(X_os)</span><br><span class="line">a1[<span class="string">&quot;259&quot;</span>] = y_os</span><br><span class="line">a1.columns = train.columns <span class="comment">#添加列名</span></span><br><span class="line">a1</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>CASH_C_EQUIV</th><th>NOTES_RECEIV</th><th>AR</th><th>PREPAYMENT</th><th>INT_RECEIV</th><th>OTH_RECEIV</th><th>INVENTORIES</th><th>OTH_CA</th><th>T_CA</th><th>AVAIL_FOR_SALE_FA</th><th>...</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th><th>FLAG</th></tr></thead><tbody><tr><th>0</th><td>-0.110544</td><td>-0.106696</td><td>-0.161667</td><td>-0.182694</td><td>-0.067294</td><td>-0.177580</td><td>-0.271929</td><td>-0.054680</td><td>-0.201905</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>1</th><td>-0.036496</td><td>1.088871</td><td>-0.182107</td><td>-0.052401</td><td>-0.085668</td><td>-0.026558</td><td>0.016419</td><td>-0.171927</td><td>0.060346</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>2</th><td>0.070766</td><td>-0.189223</td><td>0.057981</td><td>-0.140868</td><td>0.021829</td><td>-0.115114</td><td>-0.100801</td><td>0.073932</td><td>-0.023286</td><td>-0.110754</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>3</th><td>-0.039637</td><td>-0.205146</td><td>-0.184401</td><td>-0.159863</td><td>-0.062639</td><td>-0.060387</td><td>-0.197651</td><td>0.346521</td><td>-0.105029</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>4</th><td>-0.244743</td><td>-0.199970</td><td>-0.265148</td><td>-0.148300</td><td>-0.085668</td><td>-0.182752</td><td>-0.279125</td><td>-0.178592</td><td>-0.283117</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13457</th><td>-0.194605</td><td>-0.204111</td><td>-0.235016</td><td>-0.192665</td><td>-0.095194</td><td>-0.166159</td><td>-0.266567</td><td>-0.157112</td><td>-0.255136</td><td>-0.082809</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>1.0</td></tr><tr><th>13458</th><td>-0.231584</td><td>-0.196071</td><td>-0.240270</td><td>-0.175277</td><td>-0.085668</td><td>0.100651</td><td>-0.104562</td><td>-0.135625</td><td>-0.215914</td><td>-0.093468</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>1.0</td></tr><tr><th>13459</th><td>-0.172396</td><td>-0.090448</td><td>-0.126067</td><td>-0.083162</td><td>-0.085668</td><td>-0.109957</td><td>-0.217281</td><td>-0.088728</td><td>-0.182285</td><td>-0.087742</td><td>...</td><td>-0.459342</td><td>-0.013455</td><td>-0.022908</td><td>-0.067021</td><td>-0.013149</td><td>-0.008900</td><td>-0.020502</td><td>-0.563696</td><td>-0.051747</td><td>1.0</td></tr><tr><th>13460</th><td>0.220213</td><td>0.428407</td><td>0.539064</td><td>0.129878</td><td>0.930931</td><td>0.152119</td><td>0.261990</td><td>0.167506</td><td>0.343409</td><td>-0.036143</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>1.0</td></tr><tr><th>13461</th><td>0.015222</td><td>0.092724</td><td>0.156657</td><td>0.054408</td><td>-0.085668</td><td>-0.104527</td><td>0.074379</td><td>-0.154946</td><td>0.042608</td><td>-0.085088</td><td>...</td><td>-0.462918</td><td>0.015973</td><td>-0.025581</td><td>0.770781</td><td>0.029360</td><td>-0.008998</td><td>0.032707</td><td>-0.261838</td><td>0.219923</td><td>1.0</td></tr></tbody></table><p>13462 rows × 260 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a2 = a1.drop(<span class="string">&quot;FLAG&quot;</span>,axis=<span class="number">1</span>)</span><br><span class="line">a2</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>CASH_C_EQUIV</th><th>NOTES_RECEIV</th><th>AR</th><th>PREPAYMENT</th><th>INT_RECEIV</th><th>OTH_RECEIV</th><th>INVENTORIES</th><th>OTH_CA</th><th>T_CA</th><th>AVAIL_FOR_SALE_FA</th><th>...</th><th>AP_TURNOVER</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th></tr></thead><tbody><tr><th>0</th><td>-0.110544</td><td>-0.106696</td><td>-0.161667</td><td>-0.182694</td><td>-0.067294</td><td>-0.177580</td><td>-0.271929</td><td>-0.054680</td><td>-0.201905</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>1</th><td>-0.036496</td><td>1.088871</td><td>-0.182107</td><td>-0.052401</td><td>-0.085668</td><td>-0.026558</td><td>0.016419</td><td>-0.171927</td><td>0.060346</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>2</th><td>0.070766</td><td>-0.189223</td><td>0.057981</td><td>-0.140868</td><td>0.021829</td><td>-0.115114</td><td>-0.100801</td><td>0.073932</td><td>-0.023286</td><td>-0.110754</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>3</th><td>-0.039637</td><td>-0.205146</td><td>-0.184401</td><td>-0.159863</td><td>-0.062639</td><td>-0.060387</td><td>-0.197651</td><td>0.346521</td><td>-0.105029</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>4</th><td>-0.244743</td><td>-0.199970</td><td>-0.265148</td><td>-0.148300</td><td>-0.085668</td><td>-0.182752</td><td>-0.279125</td><td>-0.178592</td><td>-0.283117</td><td>-0.087742</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13457</th><td>-0.194605</td><td>-0.204111</td><td>-0.235016</td><td>-0.192665</td><td>-0.095194</td><td>-0.166159</td><td>-0.266567</td><td>-0.157112</td><td>-0.255136</td><td>-0.082809</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13458</th><td>-0.231584</td><td>-0.196071</td><td>-0.240270</td><td>-0.175277</td><td>-0.085668</td><td>0.100651</td><td>-0.104562</td><td>-0.135625</td><td>-0.215914</td><td>-0.093468</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13459</th><td>-0.172396</td><td>-0.090448</td><td>-0.126067</td><td>-0.083162</td><td>-0.085668</td><td>-0.109957</td><td>-0.217281</td><td>-0.088728</td><td>-0.182285</td><td>-0.087742</td><td>...</td><td>0.103209</td><td>-0.459342</td><td>-0.013455</td><td>-0.022908</td><td>-0.067021</td><td>-0.013149</td><td>-0.008900</td><td>-0.020502</td><td>-0.563696</td><td>-0.051747</td></tr><tr><th>13460</th><td>0.220213</td><td>0.428407</td><td>0.539064</td><td>0.129878</td><td>0.930931</td><td>0.152119</td><td>0.261990</td><td>0.167506</td><td>0.343409</td><td>-0.036143</td><td>...</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13461</th><td>0.015222</td><td>0.092724</td><td>0.156657</td><td>0.054408</td><td>-0.085668</td><td>-0.104527</td><td>0.074379</td><td>-0.154946</td><td>0.042608</td><td>-0.085088</td><td>...</td><td>-0.040714</td><td>-0.462918</td><td>0.015973</td><td>-0.025581</td><td>0.770781</td><td>0.029360</td><td>-0.008998</td><td>0.032707</td><td>-0.261838</td><td>0.219923</td></tr></tbody></table><p>13462 rows × 259 columns</p></div><h2 id="划分训练集-验证集">划分训练集、验证集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#前 5 年制造业数据分别进行训练集与验证集的切割</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line">train_data,test_data1 = train_test_split(a1,test_size = <span class="number">0.2</span>,random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#验证集</span></span><br><span class="line">test_data1</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>CASH_C_EQUIV</th><th>NOTES_RECEIV</th><th>AR</th><th>PREPAYMENT</th><th>INT_RECEIV</th><th>OTH_RECEIV</th><th>INVENTORIES</th><th>OTH_CA</th><th>T_CA</th><th>AVAIL_FOR_SALE_FA</th><th>...</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th><th>FLAG</th></tr></thead><tbody><tr><th>10307</th><td>-0.237276</td><td>-0.149240</td><td>-0.209804</td><td>-0.164470</td><td>-0.085668</td><td>-0.159014</td><td>-0.254104</td><td>-0.178466</td><td>-0.256564</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>6913</th><td>2.860131</td><td>1.594538</td><td>0.480208</td><td>2.647223</td><td>-0.085668</td><td>1.097509</td><td>8.681112</td><td>1.615339</td><td>3.903271</td><td>0.161419</td><td>...</td><td>-1.074846</td><td>-0.055897</td><td>-0.007669</td><td>-0.055792</td><td>-0.012656</td><td>-0.009343</td><td>-0.045661</td><td>-0.929869</td><td>-0.047602</td><td>0.0</td></tr><tr><th>7530</th><td>-0.236536</td><td>-0.178238</td><td>-0.227843</td><td>-0.184537</td><td>-0.085668</td><td>-0.175392</td><td>-0.267297</td><td>-0.177575</td><td>-0.268344</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>8204</th><td>-0.247465</td><td>-0.196230</td><td>-0.194191</td><td>-0.192289</td><td>-0.085668</td><td>-0.174138</td><td>-0.264405</td><td>-0.158679</td><td>-0.264602</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>11212</th><td>0.204918</td><td>-0.167106</td><td>0.011418</td><td>-0.155947</td><td>0.087527</td><td>-0.077206</td><td>0.006010</td><td>-0.041689</td><td>0.031319</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>11098</th><td>-0.204823</td><td>-0.191856</td><td>-0.257564</td><td>-0.195262</td><td>-0.085668</td><td>-0.181840</td><td>-0.262093</td><td>-0.140187</td><td>-0.261923</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>451</th><td>-0.146761</td><td>-0.059989</td><td>-0.141490</td><td>-0.150467</td><td>-0.087393</td><td>-0.178277</td><td>-0.149462</td><td>-0.135039</td><td>-0.148100</td><td>-0.064996</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>5634</th><td>-0.217310</td><td>-0.048995</td><td>-0.150073</td><td>-0.185264</td><td>-0.085668</td><td>-0.147963</td><td>-0.269352</td><td>-0.144624</td><td>-0.223935</td><td>-0.085432</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>4379</th><td>-0.225533</td><td>-0.153682</td><td>-0.128768</td><td>-0.162863</td><td>-0.111326</td><td>-0.171458</td><td>-0.151384</td><td>0.109614</td><td>-0.174713</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>7712</th><td>-0.229782</td><td>-0.188186</td><td>-0.269640</td><td>-0.172389</td><td>-0.085668</td><td>-0.171999</td><td>-0.278531</td><td>-0.171582</td><td>-0.279448</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr></tbody></table><p>2693 rows × 260 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练集</span></span><br><span class="line">train_data</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>CASH_C_EQUIV</th><th>NOTES_RECEIV</th><th>AR</th><th>PREPAYMENT</th><th>INT_RECEIV</th><th>OTH_RECEIV</th><th>INVENTORIES</th><th>OTH_CA</th><th>T_CA</th><th>AVAIL_FOR_SALE_FA</th><th>...</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th><th>FLAG</th></tr></thead><tbody><tr><th>11732</th><td>-0.115619</td><td>-0.159654</td><td>-0.215413</td><td>-0.066286</td><td>-0.055511</td><td>-0.135853</td><td>-0.226678</td><td>-0.152113</td><td>-0.203331</td><td>-0.087742</td><td>...</td><td>2.124952</td><td>-0.047612</td><td>-0.005608</td><td>-0.059694</td><td>-0.012875</td><td>-0.009210</td><td>-0.042106</td><td>0.674642</td><td>0.081817</td><td>1.0</td></tr><tr><th>2849</th><td>-0.232070</td><td>-0.138400</td><td>-0.136509</td><td>-0.174268</td><td>-0.085668</td><td>-0.166162</td><td>-0.091276</td><td>-0.171693</td><td>-0.196572</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>4938</th><td>0.147070</td><td>0.316345</td><td>0.139180</td><td>0.228339</td><td>0.028565</td><td>1.242537</td><td>-0.003413</td><td>-0.167509</td><td>0.159136</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>10029</th><td>-0.214163</td><td>-0.154632</td><td>-0.230625</td><td>-0.187055</td><td>-0.085668</td><td>-0.165990</td><td>-0.213737</td><td>-0.150521</td><td>-0.240806</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>5420</th><td>-0.210466</td><td>-0.171303</td><td>-0.145414</td><td>-0.145187</td><td>-0.085668</td><td>-0.153739</td><td>-0.053173</td><td>-0.062340</td><td>-0.168963</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13123</th><td>-0.244645</td><td>-0.113926</td><td>-0.200190</td><td>-0.112910</td><td>-0.095363</td><td>-0.145159</td><td>-0.109428</td><td>-0.093625</td><td>-0.201378</td><td>-0.092453</td><td>...</td><td>-0.958218</td><td>0.086090</td><td>-0.028829</td><td>-0.063935</td><td>-0.013042</td><td>-0.007976</td><td>0.044354</td><td>-1.065248</td><td>-0.053682</td><td>1.0</td></tr><tr><th>3264</th><td>-0.230011</td><td>-0.182265</td><td>-0.250535</td><td>-0.182594</td><td>-0.114804</td><td>-0.176142</td><td>-0.289794</td><td>-0.178597</td><td>-0.276976</td><td>-0.087742</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>9845</th><td>-0.078908</td><td>-0.201787</td><td>-0.191256</td><td>-0.195170</td><td>-0.085668</td><td>-0.155015</td><td>-0.258678</td><td>-0.178345</td><td>-0.205729</td><td>-0.087742</td><td>...</td><td>-0.812152</td><td>-0.054565</td><td>0.101067</td><td>-0.071234</td><td>-0.013280</td><td>-0.009285</td><td>-0.052963</td><td>-1.054317</td><td>-0.045676</td><td>1.0</td></tr><tr><th>10799</th><td>-0.239831</td><td>-0.174050</td><td>-0.177255</td><td>-0.192585</td><td>-0.085668</td><td>-0.101249</td><td>-0.273990</td><td>-0.151724</td><td>-0.254010</td><td>-0.103202</td><td>...</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td><td>0.0</td></tr><tr><th>2732</th><td>1.702119</td><td>0.274794</td><td>-0.037051</td><td>0.189707</td><td>2.197139</td><td>-0.087228</td><td>0.200058</td><td>-0.144783</td><td>0.668527</td><td>-0.087742</td><td>...</td><td>0.010898</td><td>-0.026220</td><td>-0.022478</td><td>-0.055215</td><td>-0.012707</td><td>-0.009076</td><td>-0.031109</td><td>0.198842</td><td>-0.051366</td><td>0.0</td></tr></tbody></table><p>10769 rows × 260 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#删除验证集FLAG</span></span><br><span class="line">test_data2=test_data1.drop(<span class="string">&quot;FLAG&quot;</span>,axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h1 id="造假指标模型建立">造假指标模型建立</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> auc</span><br><span class="line"><span class="comment">#特征重要性选择</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> plot_importance</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练集数据</span></span><br><span class="line">X_train=np.array(train_data.iloc[:,:<span class="number">259</span>])</span><br><span class="line">y_train =np.array(train_data[<span class="string">&quot;FLAG&quot;</span>])</span><br><span class="line"><span class="comment">#验证集数据</span></span><br><span class="line">y=np.array(test_data1[<span class="string">&quot;FLAG&quot;</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">feature_1 = a1.drop(<span class="string">&#x27;FLAG&#x27;</span>,axis = <span class="number">1</span>)</span><br><span class="line">feature_1</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:right"><th></th><th>CASH_C_EQUIV</th><th>NOTES_RECEIV</th><th>AR</th><th>PREPAYMENT</th><th>INT_RECEIV</th><th>OTH_RECEIV</th><th>INVENTORIES</th><th>OTH_CA</th><th>T_CA</th><th>AVAIL_FOR_SALE_FA</th><th>LT_EQUITY_INVEST</th><th>INVEST_REAL_ESTATE</th><th>FIXED_ASSETS</th><th>CIP</th><th>INTAN_ASSETS</th><th>GOODWILL</th><th>LT_AMOR_EXP</th><th>DEFER_TAX_ASSETS</th><th>OTH_NCA</th><th>T_NCA</th><th>T_ASSETS</th><th>ST_BORR</th><th>NOTES_PAYABLE</th><th>AP</th><th>ADVANCE_RECEIPTS</th><th>PAYROLL_PAYABLE</th><th>TAXES_PAYABLE</th><th>INT_PAYABLE</th><th>DIV_PAYABLE</th><th>OTH_PAYABLE</th><th>NCL_WITHIN_1Y</th><th>OTH_CL</th><th>T_CL</th><th>LT_BORR</th><th>LT_PAYABLE</th><th>ESTIMATED_LIAB</th><th>DEFER_REVENUE</th><th>DEFER_TAX_LIAB</th><th>T_NCL</th><th>T_LIAB</th><th>PAID_IN_CAPITAL</th><th>CAPITAL_RESER</th><th>SPECIAL_RESER</th><th>SURPLUS_RESER</th><th>RETAINED_EARNINGS</th><th>T_EQUITY_ATTR_P</th><th>MINORITY_INT</th><th>T_SH_EQUITY</th><th>T_LIAB_EQUITY</th><th>OTH_COMPRE_INCOME</th><th>C_PAID_OTH_FINAN_A</th><th>N_CF_FR_INVEST_A</th><th>C_FR_BORR</th><th>N_CF_OPERATE_A</th><th>C_FR_CAP_CONTR</th><th>C_PAID_INVEST</th><th>C_FR_OTH_FINAN_A</th><th>C_PAID_OTH_INVEST_A</th><th>C_INF_FR_INVEST_A</th><th>C_PAID_G_S</th><th>...</th><th>TSE_TA</th><th>C_TA</th><th>TEAP_IC</th><th>LT_AMOR_EXP_TA</th><th>NCA_TA</th><th>ST_BORR_TA</th><th>NCL_TA</th><th>EQU_MULTIPLIER</th><th>CAP_FIX_RATIO</th><th>N_TAN_A_TA</th><th>REPAY_TA</th><th>ID_IC</th><th>AP_TA</th><th>INVEN_TA</th><th>CL_TA</th><th>ADV_R_TA</th><th>AR_TA</th><th>TEAP_TA</th><th>T_FIXED_A_TA</th><th>FIXED_A_TA</th><th>TRE_TA</th><th>CA_TA</th><th>INTAN_A_TA</th><th>AIL_TR</th><th>VAL_CHG_P_TR</th><th>COGS_TR</th><th>SELL_EXP_TR</th><th>PERIOD_EXP_TR</th><th>INV_INC_TR</th><th>IT_TP</th><th>OPA_P_TP</th><th>OP_TR</th><th>FINAN_EXP_TR</th><th>VAL_CHG_P_TP</th><th>NI_CUT_NI</th><th>OPA_P_TR</th><th>N_NOPI_TP</th><th>R_TR</th><th>NOPG_TR</th><th>NI_TR</th><th>TCOGS_TR</th><th>TP_TR</th><th>NOPL_TR</th><th>ADMIN_EXP_TR</th><th>EBITDA_TR</th><th>BTAX_SURCHG_TR</th><th>IT_TR</th><th>EBIT_TR</th><th>OP_TP</th><th>DAYS_AR</th><th>AP_TURNOVER</th><th>CA_TURNOVER</th><th>OPER_CYCLE</th><th>INVEN_TURNOVER</th><th>FA_TURNOVER</th><th>TFA_TURNOVER</th><th>DAYS_AP</th><th>DAYS_INVEN</th><th>TA_TURNOVER</th><th>AR_TURNOVER</th></tr></thead><tbody><tr><th>0</th><td>-0.110544</td><td>-0.106696</td><td>-0.161667</td><td>-0.182694</td><td>-0.067294</td><td>-0.177580</td><td>-0.271929</td><td>-0.054680</td><td>-0.201905</td><td>-0.087742</td><td>-0.142028</td><td>-0.086266</td><td>-0.200848</td><td>-0.164105</td><td>-0.277532</td><td>-0.163757</td><td>-0.234584</td><td>-0.116027</td><td>-0.114840</td><td>-0.232795</td><td>-0.228647</td><td>-0.229273</td><td>-0.225301</td><td>-0.204865</td><td>-0.163052</td><td>-0.185749</td><td>-0.160000</td><td>-0.198005</td><td>-0.077002</td><td>-0.183300</td><td>-0.187825</td><td>-0.081143</td><td>-0.254193</td><td>-0.203991</td><td>-0.139548</td><td>-0.074228</td><td>-0.097049</td><td>-0.109180</td><td>-0.209598</td><td>-0.257919</td><td>-0.252988</td><td>0.005258</td><td>-0.146179</td><td>-0.153425</td><td>-0.171217</td><td>-0.157934</td><td>-0.154017</td><td>-0.167159</td><td>-0.228648</td><td>-0.048196</td><td>-0.157168</td><td>0.275978</td><td>-0.286845</td><td>-0.143991</td><td>-0.194064</td><td>-0.048096</td><td>-0.153902</td><td>-0.159625</td><td>-0.019451</td><td>-0.183022</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>1</th><td>-0.036496</td><td>1.088871</td><td>-0.182107</td><td>-0.052401</td><td>-0.085668</td><td>-0.026558</td><td>0.016419</td><td>-0.171927</td><td>0.060346</td><td>-0.087742</td><td>-0.153631</td><td>-0.086266</td><td>-0.186912</td><td>-0.173041</td><td>-0.111736</td><td>-0.163757</td><td>-0.172424</td><td>-0.023101</td><td>-0.114840</td><td>-0.209060</td><td>-0.067471</td><td>-0.229273</td><td>0.827724</td><td>0.093545</td><td>0.092487</td><td>0.069331</td><td>0.087165</td><td>-0.198005</td><td>-0.077002</td><td>-0.053152</td><td>-0.187825</td><td>-0.076646</td><td>0.043979</td><td>-0.150792</td><td>-0.139548</td><td>-0.074228</td><td>0.100215</td><td>-0.109180</td><td>-0.186920</td><td>-0.010804</td><td>-0.109135</td><td>-0.403590</td><td>-0.146179</td><td>0.015458</td><td>0.038215</td><td>-0.141095</td><td>-0.154017</td><td>-0.152307</td><td>-0.067472</td><td>-0.048196</td><td>-0.157168</td><td>0.182495</td><td>-0.232185</td><td>0.099247</td><td>-0.194064</td><td>-0.121115</td><td>-0.153902</td><td>-0.159625</td><td>-0.154439</td><td>-0.020811</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>2</th><td>0.070766</td><td>-0.189223</td><td>0.057981</td><td>-0.140868</td><td>0.021829</td><td>-0.115114</td><td>-0.100801</td><td>0.073932</td><td>-0.023286</td><td>-0.110754</td><td>-0.067454</td><td>-0.120642</td><td>-0.200108</td><td>0.077432</td><td>-0.148904</td><td>0.586702</td><td>-0.089601</td><td>-0.113231</td><td>-0.059961</td><td>-0.105702</td><td>-0.064816</td><td>-0.316157</td><td>-0.231363</td><td>-0.137904</td><td>-0.011700</td><td>-0.191030</td><td>-0.024851</td><td>-0.198005</td><td>-0.105756</td><td>-0.108134</td><td>-0.187825</td><td>-0.076646</td><td>-0.200263</td><td>-0.150792</td><td>-0.139548</td><td>-0.074228</td><td>0.260842</td><td>-0.062466</td><td>-0.163225</td><td>-0.202685</td><td>-0.029154</td><td>0.651345</td><td>-0.146179</td><td>-0.042070</td><td>-0.044831</td><td>0.188303</td><td>-0.064006</td><td>0.157133</td><td>-0.064817</td><td>-0.048196</td><td>-0.157168</td><td>-0.431703</td><td>-0.250391</td><td>0.005059</td><td>-0.243632</td><td>0.327603</td><td>-0.153902</td><td>-0.159625</td><td>0.228867</td><td>-0.158202</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>3</th><td>-0.039637</td><td>-0.205146</td><td>-0.184401</td><td>-0.159863</td><td>-0.062639</td><td>-0.060387</td><td>-0.197651</td><td>0.346521</td><td>-0.105029</td><td>-0.087742</td><td>-0.120960</td><td>-0.086266</td><td>-0.221463</td><td>-0.199303</td><td>-0.177723</td><td>-0.171951</td><td>-0.027574</td><td>-0.127111</td><td>-0.117747</td><td>-0.236460</td><td>-0.175166</td><td>-0.230604</td><td>-0.164503</td><td>-0.125771</td><td>-0.142193</td><td>-0.045072</td><td>-0.156540</td><td>-0.209112</td><td>-0.077002</td><td>-0.148004</td><td>-0.242135</td><td>-0.076646</td><td>-0.188544</td><td>-0.116849</td><td>-0.139548</td><td>-0.074228</td><td>-0.128884</td><td>-0.039623</td><td>-0.162012</td><td>-0.192893</td><td>-0.286260</td><td>0.076386</td><td>-0.146179</td><td>-0.171182</td><td>-0.131627</td><td>-0.123079</td><td>-0.177217</td><td>-0.135453</td><td>-0.175168</td><td>-0.062454</td><td>-0.157168</td><td>0.120646</td><td>-0.198916</td><td>-0.093394</td><td>-0.245538</td><td>0.044030</td><td>-0.189950</td><td>0.105294</td><td>0.073860</td><td>-0.109958</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>4</th><td>-0.244743</td><td>-0.199970</td><td>-0.265148</td><td>-0.148300</td><td>-0.085668</td><td>-0.182752</td><td>-0.279125</td><td>-0.178592</td><td>-0.283117</td><td>-0.087742</td><td>-0.120960</td><td>-0.086266</td><td>-0.282834</td><td>-0.196378</td><td>-0.306345</td><td>-0.163757</td><td>-0.189353</td><td>-0.135653</td><td>-0.114840</td><td>-0.288391</td><td>-0.302069</td><td>-0.312094</td><td>-0.194654</td><td>-0.204394</td><td>-0.168588</td><td>-0.229982</td><td>-0.185895</td><td>-0.217441</td><td>-0.108710</td><td>-0.183572</td><td>-0.187825</td><td>-0.076646</td><td>-0.259576</td><td>-0.150792</td><td>-0.139548</td><td>-0.074228</td><td>-0.162071</td><td>-0.109180</td><td>-0.218931</td><td>-0.264605</td><td>-0.401198</td><td>-0.402463</td><td>-0.146179</td><td>-0.176925</td><td>-0.219024</td><td>-0.355697</td><td>-0.179565</td><td>-0.341002</td><td>-0.302070</td><td>-0.048196</td><td>-0.176421</td><td>0.224868</td><td>-0.285642</td><td>-0.201230</td><td>-0.194064</td><td>-0.121115</td><td>-0.153902</td><td>-0.159625</td><td>-0.156845</td><td>-0.177266</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>...</th><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr><tr><th>13457</th><td>-0.194605</td><td>-0.204111</td><td>-0.235016</td><td>-0.192665</td><td>-0.095194</td><td>-0.166159</td><td>-0.266567</td><td>-0.157112</td><td>-0.255136</td><td>-0.082809</td><td>-0.144837</td><td>-0.086266</td><td>-0.234505</td><td>-0.179108</td><td>-0.247421</td><td>-0.173251</td><td>-0.202890</td><td>-0.117034</td><td>-0.115165</td><td>-0.249601</td><td>-0.267204</td><td>-0.241517</td><td>-0.233453</td><td>-0.203503</td><td>-0.160887</td><td>-0.201682</td><td>-0.171888</td><td>-0.198005</td><td>-0.077002</td><td>-0.156267</td><td>-0.187825</td><td>-0.076646</td><td>-0.251653</td><td>-0.150792</td><td>-0.139548</td><td>-0.085263</td><td>-0.142678</td><td>-0.124578</td><td>-0.215774</td><td>-0.257401</td><td>-0.138162</td><td>-0.345235</td><td>-0.146179</td><td>-0.164382</td><td>-0.194570</td><td>-0.269117</td><td>-0.180658</td><td>-0.264808</td><td>-0.267205</td><td>-0.048232</td><td>-0.157168</td><td>0.282769</td><td>-0.277337</td><td>-0.214423</td><td>-0.237723</td><td>-0.089799</td><td>-0.174903</td><td>-0.159625</td><td>-0.081430</td><td>-0.168416</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13458</th><td>-0.231584</td><td>-0.196071</td><td>-0.240270</td><td>-0.175277</td><td>-0.085668</td><td>0.100651</td><td>-0.104562</td><td>-0.135625</td><td>-0.215914</td><td>-0.093468</td><td>-0.075270</td><td>0.064067</td><td>-0.170791</td><td>-0.197127</td><td>-0.291951</td><td>-0.174709</td><td>-0.235937</td><td>-0.132742</td><td>-0.119921</td><td>-0.205796</td><td>-0.223482</td><td>-0.183847</td><td>-0.242438</td><td>-0.113028</td><td>-0.165859</td><td>-0.198643</td><td>-0.352867</td><td>-0.101828</td><td>-0.078867</td><td>0.014294</td><td>-0.243134</td><td>-0.077372</td><td>-0.178927</td><td>-0.182819</td><td>-0.139548</td><td>0.072025</td><td>-0.158947</td><td>-0.109180</td><td>-0.191181</td><td>-0.192376</td><td>-0.015725</td><td>-0.131649</td><td>-0.146179</td><td>-0.104321</td><td>-0.381811</td><td>-0.255928</td><td>-0.208644</td><td>-0.257609</td><td>-0.223483</td><td>-0.037582</td><td>-0.157168</td><td>0.219093</td><td>-0.215293</td><td>-0.297951</td><td>-0.196203</td><td>-0.126649</td><td>0.038585</td><td>-0.159625</td><td>-0.140010</td><td>-0.169934</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13459</th><td>-0.172396</td><td>-0.090448</td><td>-0.126067</td><td>-0.083162</td><td>-0.085668</td><td>-0.109957</td><td>-0.217281</td><td>-0.088728</td><td>-0.182285</td><td>-0.087742</td><td>-0.123844</td><td>-0.120632</td><td>-0.234071</td><td>-0.054888</td><td>-0.188660</td><td>-0.163757</td><td>-0.128242</td><td>-0.031042</td><td>-0.114840</td><td>-0.221879</td><td>-0.212135</td><td>-0.252805</td><td>-0.194654</td><td>-0.079903</td><td>-0.078436</td><td>-0.206288</td><td>-0.167967</td><td>0.184241</td><td>-0.077002</td><td>-0.023900</td><td>-0.187825</td><td>-0.076646</td><td>-0.186352</td><td>-0.150792</td><td>-0.139548</td><td>0.849701</td><td>-0.147337</td><td>-0.109180</td><td>-0.130924</td><td>-0.183368</td><td>0.092909</td><td>-0.037259</td><td>-0.222978</td><td>-0.104361</td><td>-0.472813</td><td>-0.247493</td><td>-0.145101</td><td>-0.243325</td><td>-0.212136</td><td>-0.048196</td><td>-0.157168</td><td>0.284709</td><td>-0.227859</td><td>-0.224250</td><td>-0.194064</td><td>-0.041249</td><td>-0.132306</td><td>-0.192049</td><td>-0.032639</td><td>-0.181799</td><td>...</td><td>0.011101</td><td>-0.091564</td><td>-0.763986</td><td>-0.071247</td><td>0.996515</td><td>-0.014163</td><td>-0.009115</td><td>0.068415</td><td>0.295576</td><td>0.011159</td><td>-0.254426</td><td>0.988053</td><td>0.000208</td><td>0.124612</td><td>-0.011954</td><td>-0.011675</td><td>0.593479</td><td>0.011130</td><td>2.383589</td><td>2.401008</td><td>0.011301</td><td>-1.000220</td><td>0.351214</td><td>-0.008270</td><td>-0.051766</td><td>1.752778</td><td>-0.611433</td><td>-0.008477</td><td>-0.053741</td><td>-0.113486</td><td>0.027801</td><td>0.008361</td><td>-0.008459</td><td>-0.013867</td><td>0.070320</td><td>0.008370</td><td>-0.032261</td><td>0.038886</td><td>-0.008778</td><td>0.008361</td><td>-0.008370</td><td>0.008355</td><td>-0.008532</td><td>-0.008450</td><td>-0.472817</td><td>0.014996</td><td>-0.339346</td><td>0.008169</td><td>0.032168</td><td>0.010236</td><td>0.103209</td><td>-0.459342</td><td>-0.013455</td><td>-0.022908</td><td>-0.067021</td><td>-0.013149</td><td>-0.008900</td><td>-0.020502</td><td>-0.563696</td><td>-0.051747</td></tr><tr><th>13460</th><td>0.220213</td><td>0.428407</td><td>0.539064</td><td>0.129878</td><td>0.930931</td><td>0.152119</td><td>0.261990</td><td>0.167506</td><td>0.343409</td><td>-0.036143</td><td>-0.133788</td><td>-0.086266</td><td>0.574080</td><td>1.685421</td><td>0.752913</td><td>-0.025926</td><td>-0.010816</td><td>0.002251</td><td>0.311119</td><td>0.653651</td><td>0.514408</td><td>0.162320</td><td>-0.251056</td><td>0.137400</td><td>-0.154652</td><td>-0.148068</td><td>0.305776</td><td>2.339665</td><td>-0.077002</td><td>-0.083185</td><td>-0.018381</td><td>0.503922</td><td>0.097436</td><td>-0.155138</td><td>-0.158031</td><td>-0.074228</td><td>0.376548</td><td>0.404251</td><td>1.020602</td><td>0.333509</td><td>-0.014059</td><td>1.199035</td><td>-0.146179</td><td>0.190460</td><td>0.870264</td><td>0.871184</td><td>-0.024417</td><td>0.765729</td><td>0.514407</td><td>-0.079826</td><td>0.026608</td><td>-0.935087</td><td>0.135455</td><td>0.398947</td><td>-0.243537</td><td>-0.125528</td><td>-0.021834</td><td>-0.024758</td><td>-0.114136</td><td>0.050575</td><td>...</td><td>0.011147</td><td>-0.127655</td><td>0.007816</td><td>-0.090990</td><td>-0.018944</td><td>-0.014594</td><td>-0.009392</td><td>-0.020234</td><td>-0.079771</td><td>0.011144</td><td>-0.158489</td><td>-0.020358</td><td>-0.016036</td><td>-0.144829</td><td>-0.011974</td><td>-0.010509</td><td>-0.168016</td><td>0.011145</td><td>-0.132080</td><td>-0.126937</td><td>0.011562</td><td>0.019110</td><td>-0.139211</td><td>-0.008475</td><td>-0.044078</td><td>0.087840</td><td>-0.156706</td><td>-0.008489</td><td>-0.041648</td><td>0.010630</td><td>0.016545</td><td>0.008475</td><td>-0.008480</td><td>-0.011569</td><td>0.034511</td><td>0.008481</td><td>-0.022897</td><td>0.038886</td><td>-0.008784</td><td>0.008472</td><td>-0.008481</td><td>0.008471</td><td>-0.008531</td><td>-0.008533</td><td>-0.003868</td><td>-0.044050</td><td>-0.054146</td><td>0.008459</td><td>0.022926</td><td>-0.012153</td><td>-0.071554</td><td>-0.120861</td><td>-0.030988</td><td>-0.022326</td><td>-0.046674</td><td>-0.012361</td><td>-0.008952</td><td>-0.031444</td><td>-0.112856</td><td>-0.047602</td></tr><tr><th>13461</th><td>0.015222</td><td>0.092724</td><td>0.156657</td><td>0.054408</td><td>-0.085668</td><td>-0.104527</td><td>0.074379</td><td>-0.154946</td><td>0.042608</td><td>-0.085088</td><td>-0.117501</td><td>-0.086266</td><td>0.083504</td><td>-0.131142</td><td>-0.256025</td><td>-0.170433</td><td>0.338018</td><td>-0.074333</td><td>0.013288</td><td>-0.046307</td><td>0.001719</td><td>-0.154665</td><td>0.307370</td><td>0.160793</td><td>-0.096559</td><td>-0.026013</td><td>-0.139392</td><td>-0.198598</td><td>-0.077002</td><td>0.065349</td><td>0.128240</td><td>-0.076646</td><td>0.029736</td><td>0.175793</td><td>-0.115495</td><td>-0.083274</td><td>0.024891</td><td>-0.113892</td><td>0.041858</td><td>0.034694</td><td>-0.113173</td><td>0.029863</td><td>-0.146179</td><td>-0.023991</td><td>-0.028819</td><td>-0.031130</td><td>-0.140034</td><td>-0.050337</td><td>0.001718</td><td>-0.020687</td><td>-0.167773</td><td>0.198412</td><td>-0.077565</td><td>0.225320</td><td>-0.194064</td><td>-0.131067</td><td>-0.063616</td><td>-0.128632</td><td>-0.114486</td><td>-0.004891</td><td>...</td><td>0.011075</td><td>0.102449</td><td>-0.414292</td><td>-0.090990</td><td>-0.811893</td><td>-0.014594</td><td>-0.009182</td><td>0.034719</td><td>-0.130274</td><td>0.011120</td><td>-0.128349</td><td>0.499511</td><td>-0.014519</td><td>1.970255</td><td>-0.011936</td><td>-0.004084</td><td>-0.587565</td><td>0.011085</td><td>-0.768414</td><td>-0.818383</td><td>0.011551</td><td>0.806651</td><td>-0.422075</td><td>-0.008475</td><td>-0.038851</td><td>0.377146</td><td>-0.372627</td><td>-0.008509</td><td>-0.038106</td><td>0.069489</td><td>0.016263</td><td>0.008474</td><td>-0.008479</td><td>-0.008330</td><td>0.041396</td><td>0.008481</td><td>-0.024758</td><td>0.015333</td><td>-0.008814</td><td>0.008469</td><td>-0.008481</td><td>0.008468</td><td>-0.008534</td><td>-0.008605</td><td>-0.058418</td><td>0.213152</td><td>-0.037802</td><td>0.008452</td><td>0.024738</td><td>-0.018517</td><td>-0.040714</td><td>-0.462918</td><td>0.015973</td><td>-0.025581</td><td>0.770781</td><td>0.029360</td><td>-0.008998</td><td>0.032707</td><td>-0.261838</td><td>0.219923</td></tr></tbody></table><p>13462 rows × 259 columns</p></div><h2 id="logistics-regression-调参过程">Logistics Regression 调参过程</h2><p>在模型中先固定参数的默认值，然后进行参数调节，进行网格搜索与专业文献查阅寻找精确度最高而又不引起模型过拟合的参数值．模型优化评价指标为 AUC 值．</p><p>在逻辑回归模型中，需要调整的参数共有 2 个：penalty 与 C, 其中 penalty 是正则化方法，C 为逻辑回归中的超参数，表示正则化强度的倒数，在模型中默认为 1，表示正则项与损失函数的比值为 1:1．当模型中的 C 越小时，会导致损失损失函数越小，从而对其惩罚更重，正则化作用越强．</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练逻辑回归模型  C调参范围 [0.05,0.1,0.2,0.3]</span></span><br><span class="line">clf1 = LogisticRegression(C=<span class="number">0.2</span>,penalty=<span class="string">&quot;l2&quot;</span>).fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line"><span class="comment">#返回预测属于股票代码的概率 </span></span><br><span class="line">y_pred_gbc = clf1.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line"></span><br><span class="line"><span class="comment">#查看召回率</span></span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc=metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.884673004897724</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#penalty调参范围:[l1、l2、none]</span></span><br><span class="line">clf2= LogisticRegression(penalty=<span class="string">&quot;none&quot;</span>).fit(X_train, y_train)</span><br><span class="line">y_pred_gbc = clf2.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc=metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9013195044655719</span><br></pre></td></tr></table></figure><p>逻辑回归属于线性判别模型，而所处理的数据集维度较高，故可能存在其他非线性模型能够表现的更好．</p><h2 id="svm-调参过程">SVM 调参过程</h2><p>SVM 需要调整的参数有 2 个，分别为 kernal 和 C，</p><p>其中 kernal 代表核方法，可选的函数有：“poly”：多项式核函数，“rbf”：高斯核函数 (径向基函数)，“linear”：线性核函数，“sigmod”：核函数．核函数在 SVM 中发挥着重要功能，在简化向量内积运算起着重要作用，其中高斯核函数在非线性分类问题上广泛应用．</p><p>C 代表错误项的惩罚系数，在软间隔分类中应用较多．C 越大，对错误样本的惩罚力度就越大，训练的样本准确率越高．但是容易产生过拟合现象，机器模型的泛化能力降低．相反，C 取较小的值时，允许训练样本中存在错误分类的样本，能够增强模型的泛化能力．</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#kernal调参范围: [&quot;linear&quot;,&quot;rbf&quot;,&quot;sigmoid&quot;,&quot;poly&quot;]   </span></span><br><span class="line">svm1 = svm.SVC(kernel=<span class="string">&#x27;rbf&#x27;</span>,probability=<span class="literal">True</span>).fit(X_train, y_train)</span><br><span class="line">y_pred_gbc = svm1.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc=metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.8988533563814463</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#kernal调参范围: [&quot;linear&quot;,&quot;rbf&quot;,&quot;sigmoid&quot;,&quot;poly&quot;]   </span></span><br><span class="line">svm2 = svm.SVC(C=<span class="number">0.003</span>,probability=<span class="literal">True</span>).fit(X_train, y_train)</span><br><span class="line">y_pred_gbc = svm2.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc=metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.8741169691731491</span><br></pre></td></tr></table></figure><h2 id="rf-调参过程">RF 调参过程</h2><p>在随机森林模型中需要调节的参数有 4 个，分别为</p><p>max_depth：树的最大深度、<br>n_estinators：树模型的数量、<br>min_samples_split：中间节点分支所需的最小样本数量、<br>min_sample_leaf：叶节点存在所需的最小样本数量．</p><p>为了防止模型出现过拟合现象，在调节其他参数时控制 max_depth=3．</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#max_depth调参范围: [3,5,7,8,11,13]  </span></span><br><span class="line">RF1 = RandomForestClassifier(max_depth=<span class="number">3</span>, random_state=<span class="number">0</span>).fit(X_train, y_train)</span><br><span class="line">y_pred_gbc = RF1.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.8762738884087198</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#n_estinators 调参范围: [300,400,500,600,700]</span></span><br><span class="line">RF2 = RandomForestClassifier(n_estimators=<span class="number">600</span>, random_state=<span class="number">0</span>,max_depth=<span class="number">3</span>).fit(X_train, y_train)</span><br><span class="line">y_pred_gbc = RF2.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.8856746374723902</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#min_samples_leaf 调参范围:   [10,20,40,60,70,80,100]</span></span><br><span class="line">RF3= RandomForestClassifier(min_samples_leaf=<span class="number">30</span>, random_state=<span class="number">0</span>,max_depth=<span class="number">3</span>).fit(X_train, y_train)</span><br><span class="line">y_pred_gbc = RF3.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.8766320944972631</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#min_samples_split 调参范围:  [60,70,80,90,110,130]</span></span><br><span class="line">RF4 = RandomForestClassifier(min_samples_split=<span class="number">80</span>, random_state=<span class="number">0</span>,max_depth=<span class="number">3</span>).fit(X_train, y_train)</span><br><span class="line">y_pred_gbc = RF4.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.8757802746566791</span><br></pre></td></tr></table></figure><h2 id="dt-调参过程">DT 调参过程</h2><p>在决策树模型中需要调整的参数共有 4 个，分别为</p><p>max_depth：树的最大深度、<br>min_samples_split：中间节点分支所需要的的最小样本量、<br>min_sample_leaf：叶节点存在所需的最小样本量、<br>max_leaf_nodes：最大叶子节点数．</p><p>为了防止模型出现过拟合现象，调节其他参数对模型的 AUC 影响时控制 max_depth=6</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#max_depth 调参范围:  [5,6,7,8,9,10]</span></span><br><span class="line">DT1 =tree.DecisionTreeClassifier(max_depth=<span class="number">6</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = DT1.predict_proba(test_data2)[:,<span class="number">1</span>]</span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9026846249879958</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#min_samples_leaf 调参范围:  [2,3,6,8]</span></span><br><span class="line">DT1 =tree.DecisionTreeClassifier(min_samples_leaf=<span class="number">3</span>,max_depth=<span class="number">6</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = DT1.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9008700662633248</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#max_leaf_nodes 调参范围:  [50,60,70,80,100]</span></span><br><span class="line">DT2 =tree.DecisionTreeClassifier(max_leaf_nodes=<span class="number">70</span>, max_depth=<span class="number">6</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = DT2.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9006472678382791</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 max_depth=6</span></span><br><span class="line"><span class="comment">#min_samples_split 调参范围:  [2,3,4,5,6,8]</span></span><br><span class="line">DT3 =tree.DecisionTreeClassifier(min_samples_split=<span class="number">3</span>,max_depth=<span class="number">6</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = DT3.predict_proba(test_data2)[:,<span class="number">1</span>]</span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9005358686257564</span><br></pre></td></tr></table></figure><h3 id="筛选在dt算法中特征重要性系数前20个指标">筛选在DT算法中特征重要性系数前20个指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DT_importances = DT3.feature_importances_*<span class="number">10000</span></span><br><span class="line">DT = pd.Series(DT_importances, index = a2.columns)</span><br><span class="line">DT = DT.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">DT = pd.DataFrame(&#123;<span class="string">&#x27;feature_importances&#x27;</span> : DT&#125;)</span><br><span class="line">DT.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:center"><th></th><th>feature_importances</th></tr></thead><tbody><tr><th>DILUTED_EPS</th><td>1876.459630</td></tr><tr><th>ESTIMATED_LIAB</th><td>1418.956658</td></tr><tr><th>RETAINED_EARNINGS</th><td>1274.737100</td></tr><tr><th>ASSETS_DISP_GAIN</th><td>1189.341616</td></tr><tr><th>C_FR_CAP_CONTR</th><td>350.146297</td></tr><tr><th>CASH_C_EQUIV</th><td>305.869870</td></tr><tr><th>DEFER_TAX_LIAB</th><td>305.319042</td></tr><tr><th>INT_RECEIV</th><td>278.811896</td></tr><tr><th>CURRENT_RATIO</th><td>254.761597</td></tr><tr><th>N_CF_FR_FINAN_A</th><td>245.185566</td></tr><tr><th>OTH_GAIN</th><td>214.434895</td></tr><tr><th>GOODWILL</th><td>207.893979</td></tr><tr><th>N_INCOME</th><td>199.309895</td></tr><tr><th>CL_TA</th><td>190.726453</td></tr><tr><th>NOPERATE_EXP</th><td>180.024039</td></tr><tr><th>OTH_CL</th><td>167.889986</td></tr><tr><th>GAIN_INVEST</th><td>160.657452</td></tr><tr><th>DIV_PAYABLE</th><td>157.439514</td></tr><tr><th>IT_TR</th><td>117.051125</td></tr><tr><th>A_J_INVEST_INCOME</th><td>101.434231</td></tr></tbody></table></div><h2 id="xgboost-调参过程">XGBoost 调参过程</h2><p>XGBoost 需要调节的参数共有 9 个，下面只介绍对该模型相对重要的两个参数：</p><p>第一个参数是 n_estimators，在 XGBoost 模型中这个参数发挥着重要作用，表示该模型中分类器的个数，该参数的值越大，模型的学习能力就会越强．</p><p>第二个参数是learning_rate，learning_rate 表示集成模型中的学习速率，又被称之为步长控制迭代速率，有效的调节该参数值能够防止模型出现过拟合现象，默认值为 0.1，调节范围为[0,1]．</p><p>为了尽可能防止模型出现过拟合，在调节其他参数的值时将学习率设定为0.001．</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> plot_importance</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#learning_rate 调参范围:  [0.001,0.002,0.003,0.0035]</span></span><br><span class="line">XGBoost1 = XGBClassifier(learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost1.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9089825218476904</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 learning_rate=0.001</span></span><br><span class="line"><span class="comment">#learning_rate 调参范围:   [100,110,120,200,300] </span></span><br><span class="line">XGBoost2 = XGBClassifier(n_estimators=<span class="number">120</span>,learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost2.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.911076058772688</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 learning_rate=1</span></span><br><span class="line"><span class="comment">#max_depth 调参范围:  [2,3,5,6,7,10]</span></span><br><span class="line">XGBoost3 = XGBClassifier(max_depth=<span class="number">6</span>,learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost3.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9089825218476904</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 learning_rate=1</span></span><br><span class="line"><span class="comment">#min_child_weight  调参范围:  [1,3,4,5,7,8]</span></span><br><span class="line">XGBoost4 = XGBClassifier(min_child_weight=<span class="number">3</span>,learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost4.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9118438490348603</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 learning_rate=1</span></span><br><span class="line"><span class="comment">#Gamma 调参范围:   [0.2,0.3,0.5,0.6,0.7,0.8]</span></span><br><span class="line">XGBoost5 = XGBClassifier(gamma=<span class="number">0.4</span>,learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost5.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9089844425237683</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 learning_rate=1</span></span><br><span class="line"><span class="comment">#Colsample_btree 调参范围:  [0.6,0.7,0.8,0.85,0.9] </span></span><br><span class="line">XGBoost7 = XGBClassifier(colsample_btree=<span class="number">0.85</span>,learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost7.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9089825218476904</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 learning_rate=1</span></span><br><span class="line"><span class="comment">#reg_alpha 调参范围:  [0.1,0.2,0.25,0.3,0.35] </span></span><br><span class="line">XGBoost8 = XGBClassifier(reg_alpha=<span class="number">0.2</span>,learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost8.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9087702871410737</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#为了防止模型出现过拟合现象,调节其他参数对模型的 AUC 影响时控制 learning_rate=1</span></span><br><span class="line"><span class="comment">#reg_lambda 调参范围: [0.15,0.3,0.5,0.8]</span></span><br><span class="line">XGBoost9 = XGBClassifier(reg_lambda=<span class="number">0.3</span>,learning_rate=<span class="number">0.001</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = XGBoost9.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9160871026601364</span><br></pre></td></tr></table></figure><h3 id="筛选在xgboost算法中特征重要性系数前20个指标">筛选在XGBoost算法中特征重要性系数前20个指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">XGBoost_importances = XGBoost9.feature_importances_*<span class="number">10000</span></span><br><span class="line">XGBoost = pd.Series(XGBoost_importances, index = a2.columns)</span><br><span class="line">XGBoost = XGBoost.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">XGBoost = pd.DataFrame(&#123;<span class="string">&#x27;feature_importances&#x27;</span> : XGBoost&#125;)</span><br><span class="line">XGBoost.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:center"><th></th><th>feature_importances</th></tr></thead><tbody><tr><th>DILUTED_EPS</th><td>1092.639893</td></tr><tr><th>ASSETS_DISP_GAIN</th><td>839.089539</td></tr><tr><th>RETAINED_EARNINGS</th><td>501.631378</td></tr><tr><th>T_CA</th><td>428.929138</td></tr><tr><th>ESTIMATED_LIAB</th><td>363.835968</td></tr><tr><th>DEFER_TAX_LIAB</th><td>311.677368</td></tr><tr><th>CURRENT_RATIO</th><td>294.901703</td></tr><tr><th>N_CF_FR_FINAN_A</th><td>284.164001</td></tr><tr><th>GOODWILL</th><td>239.289185</td></tr><tr><th>N_INCOME</th><td>238.080658</td></tr><tr><th>CL_TA</th><td>224.853226</td></tr><tr><th>INVENTORIES</th><td>224.492996</td></tr><tr><th>ROE_A</th><td>214.091843</td></tr><tr><th>NOPERATE_EXP</th><td>196.429474</td></tr><tr><th>OTH_CA</th><td>192.453537</td></tr><tr><th>OTH_CL</th><td>191.517349</td></tr><tr><th>C_FR_MINO_S_SUBS</th><td>191.478973</td></tr><tr><th>GAIN_INVEST</th><td>187.904297</td></tr><tr><th>C_INF_FR_INVEST_A</th><td>180.430847</td></tr><tr><th>CASH_C_EQUIV</th><td>178.665329</td></tr></tbody></table></div><h2 id="gbm-调参过程">GBM 调参过程</h2><p>该模型需要添加的参数共有 7 个，选取了对该模型相对重要的几个参数进行调节．</p><p>第一个参数是：max_depth：模型中树的最大深度．</p><p>第二个参数是 n_estimators：模型中分类器的数量，该参数在模型中的作用较为强大，可以有效的提升模型的学习能力．</p><p>第三个参数是 learning_rate：学习率，该参数的有效调节对模型是否会过拟合发挥着重要作用，参数的取值范围为 [0,1]，默认值为 0.1．为了能够有效的提升模型的泛化能力并且防止模型出现过拟合现象，经过网络搜索法并且查阅大量机器学习专业文献将 learning 设置为 0.0088．</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#learning_rate 调参范围:   [0.004,0.007,0.0076,0.0088,0.009]</span></span><br><span class="line">GBM1 = GradientBoostingClassifier(learning_rate=<span class="number">0.0088</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = GBM1.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9016575434552964</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#n_estimators 调参范围:  [110,120,130,140,160]</span></span><br><span class="line">GBM2 = GradientBoostingClassifier(n_estimators=<span class="number">130</span>,learning_rate=<span class="number">0.0088</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = GBM2.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9171185057140113</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Subsample 调参范围: [0.1,0.2,0.25,0.3,0.4]</span></span><br><span class="line">GBM3 = GradientBoostingClassifier(subsample=<span class="number">0.3</span>,learning_rate=<span class="number">0.0088</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = GBM3.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9131902429655239</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#min_samples_split 调参范围: [2,3,4,5,6] </span></span><br><span class="line">GBM4 = GradientBoostingClassifier(min_samples_split=<span class="number">4</span>,learning_rate=<span class="number">0.0088</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = GBM4.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9016575434552964</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#mmin_samples_leaf 调参范围: [2,3,4,6,7,9] </span></span><br><span class="line">GBM5 = GradientBoostingClassifier(min_samples_leaf=<span class="number">3</span>,learning_rate=<span class="number">0.0088</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = GBM5.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9021089023336215</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#max_depth 调参范围: [2,3,4,5,8]</span></span><br><span class="line">GBM6 = GradientBoostingClassifier(max_depth=<span class="number">3</span>,learning_rate=<span class="number">0.0088</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = GBM6.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9016575434552964</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#validation_fraction 调参范围: [0.1,0.3,0.4,0.5,0.7,0.8]</span></span><br><span class="line">GBM7 =GradientBoostingClassifier(validation_fraction=<span class="number">0.1</span>,learning_rate=<span class="number">0.0088</span>).fit(X_train,y_train)</span><br><span class="line">y_pred_gbc = GBM7.predict_proba(test_data2)[:,<span class="number">1</span>] </span><br><span class="line">fpr, tpr, thresholds = metrics.roc_curve(y,y_pred_gbc,pos_label=<span class="number">1</span>)</span><br><span class="line">roc_auc = metrics.auc(fpr, tpr)</span><br><span class="line">roc_auc</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.9016575434552964</span><br></pre></td></tr></table></figure><h3 id="筛选在gbm算法中特征重要性系数前20个指标">筛选在GBM算法中特征重要性系数前20个指标</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">GBM_importances = GBM2.feature_importances_*<span class="number">10000</span></span><br><span class="line">GBM = pd.Series(GBM_importances, index = a2.columns)</span><br><span class="line">GBM = GBM.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">GBM = pd.DataFrame(&#123;<span class="string">&#x27;feature_importances&#x27;</span> : GBM&#125;)</span><br><span class="line">GBM.head(<span class="number">20</span>)</span><br></pre></td></tr></table></figure><div><style scoped>.dataframe tbody tr th:only-of-type{vertical-align:middle}</style><table border="1" class="dataframe"><thead><tr style="text-align:center"><th></th><th>feature_importances</th></tr></thead><tbody><tr><th>DILUTED_EPS</th><td>2545.405622</td></tr><tr><th>ASSETS_DISP_GAIN</th><td>1393.862699</td></tr><tr><th>RETAINED_EARNINGS</th><td>1201.324132</td></tr><tr><th>ESTIMATED_LIAB</th><td>1123.032285</td></tr><tr><th>NCA_DISPLOSS</th><td>496.913323</td></tr><tr><th>C_FR_CAP_CONTR</th><td>429.072252</td></tr><tr><th>OTH_GAIN</th><td>392.266813</td></tr><tr><th>NOPERATE_EXP</th><td>216.007424</td></tr><tr><th>PROC_SELL_INVEST</th><td>191.362051</td></tr><tr><th>T_CA</th><td>179.957164</td></tr><tr><th>DEFER_TAX_LIAB</th><td>172.171302</td></tr><tr><th>N_CF_FR_INVEST_A</th><td>157.682156</td></tr><tr><th>INT_PAYABLE</th><td>157.357831</td></tr><tr><th>DIV_PAYABLE</th><td>103.399260</td></tr><tr><th>C_PAID_OTH_FINAN_A</th><td>95.313147</td></tr><tr><th>INT_RECEIV</th><td>87.237988</td></tr><tr><th>REV_PS</th><td>86.175900</td></tr><tr><th>C_INF_FR_INVEST_A</th><td>76.066347</td></tr><tr><th>ADVANCE_RECEIPTS</th><td>64.396530</td></tr><tr><th>T_EQUITY_ATTR_P</th><td>62.686717</td></tr></tbody></table></div></article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/t.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/t.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">Rshimmer</div><div class="post-copyright__author_desc">小平凡的记录</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="https://rshimmering.github.io/posts/fd7a19d1.html">原创</a><a class="post-copyright-title"><span onclick='rm.copyPageUrl("https://rshimmering.github.io/posts/fd7a19d1.html")'>Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业）</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="https://rshimmering.github.io/posts/fd7a19d1.html"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Python数据挖掘——基于数据挖掘的上市公司财务造假识别（制造业）&amp;url=https://rshimmering.github.io/posts/fd7a19d1.html&amp;pic=/pageimg/wallhaven-m917o9.jpg" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="rm.copyPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://Rshimmering.github.io" target="_blank">Rshimmer</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/Python/"><span class="tags-punctuation"><i class="anzhiyufont anzhiyu-icon-tag"></i></span>Python<span class="tagsPageCount">21</span></a><a class="post-meta__box__tags" href="/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>数据挖掘<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>逻辑回归<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>决策树<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>支持向量机<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/XGBoost/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>XGBoost<span class="tagsPageCount">1</span></a><a class="post-meta__box__tags" href="/tags/GBM/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>GBM<span class="tagsPageCount">1</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="/pageimg/%E4%B8%8D%E6%AD%A2%E5%BD%93%E4%B8%8B.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/befeb9c9.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/wallhaven-0w2y76.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python数据分析——教育平台的线上课程智能推荐策略（2020泰迪杯数据分析技能赛）</div></div></a></div><div class="next-post pull-right"><a href="/posts/1013dd96.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/wallhaven-g81pl3.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Tableau——超市销售额数据分析可视化</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size:1.5rem;margin-right:4px"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/6b08c33d.html" title="Python——DataFrame、List、字典相互转换"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-07-21</div><div class="title">Python——DataFrame、List、字典相互转换</div></div></a></div><div><a href="/posts/b382cbf3.html" title="Python——word文档"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/r1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-10-29</div><div class="title">Python——word文档</div></div></a></div><div><a href="/posts/ae5b425e.html" title="Python——一维转二维、二维转一维"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/R-C.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-06-25</div><div class="title">Python——一维转二维、二维转一维</div></div></a></div><div><a href="/posts/9ccf6c0f.html" title="Python——修改列名"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/2664417.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-08-14</div><div class="title">Python——修改列名</div></div></a></div><div><a href="/posts/e7cf047a.html" title="Python——写入excel"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/248307.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2024-01-14</div><div class="title">Python——写入excel</div></div></a></div><div><a href="/posts/1a2a6127.html" title="Python——保存文件"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/1198802.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2023-08-02</div><div class="title">Python——保存文件</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-top" title="点击展开"><div class="card-info-avatar"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/t.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-status-box"><div class="author-status"><g-emoji class="g-emoji" alias="writing_hand">🏃‍♀️</g-emoji><span>on Studying</span></div></div></div></div><div class="author-info__description">人生万事须自为</div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">Rshimmer</h1><div class="author-info__desc">小平凡的记录</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/Rshimmering" target="_blank" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E7%BC%BA%E5%A4%B1%E7%8E%87-%E5%B9%B6%E9%99%8D%E5%BA%8F%E6%8E%92%E5%BA%8F"><span class="toc-number">1.1.</span> <span class="toc-text">计算缺失率，并降序排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A480-%E4%BB%A5%E4%B8%8A%E7%9A%84%E7%BC%BA%E5%A4%B1%E7%8E%87"><span class="toc-number">1.2.</span> <span class="toc-text">删除80%以上的缺失率</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E7%BC%BA%E5%A4%B1%E7%8E%8720-%E5%88%B080-%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A1%AB%E5%85%85%E4%B8%AD%E4%BD%8D%E6%95%B0"><span class="toc-number">1.3.</span> <span class="toc-text">对缺失率20%到80%的数据填充中位数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E7%BC%BA%E5%A4%B1%E7%8E%8720-%E4%BB%A5%E4%B8%8B%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BD%BF%E7%94%A8knn%E5%A1%AB%E5%85%85"><span class="toc-number">1.4.</span> <span class="toc-text">对缺失率20%以下的数据使用KNN填充</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E4%B8%8E%E9%A2%84%E6%B5%8B%E6%98%AF%E5%90%A6%E9%80%A0%E5%81%87%E7%BB%93%E6%9E%9C%E6%97%A0%E5%85%B3%E7%9A%84%E7%89%B9%E5%BE%81%E5%9B%A0%E5%AD%90"><span class="toc-number">1.5.</span> <span class="toc-text">删除与预测是否造假结果无关的特征因子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%98%AF%E5%90%A6%E8%BF%98%E5%AD%98%E5%9C%A8%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">1.6.</span> <span class="toc-text">查看是否还存在缺失值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">1.7.</span> <span class="toc-text">对数据进行标准化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%92%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.</span> <span class="toc-text">划分数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E5%A4%84%E7%90%86"><span class="toc-number">2.1.</span> <span class="toc-text">样本不均衡处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86-%E9%AA%8C%E8%AF%81%E9%9B%86"><span class="toc-number">2.2.</span> <span class="toc-text">划分训练集、验证集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%A0%E5%81%87%E6%8C%87%E6%A0%87%E6%A8%A1%E5%9E%8B%E5%BB%BA%E7%AB%8B"><span class="toc-number">3.</span> <span class="toc-text">造假指标模型建立</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#logistics-regression-%E8%B0%83%E5%8F%82%E8%BF%87%E7%A8%8B"><span class="toc-number">3.1.</span> <span class="toc-text">Logistics Regression 调参过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#svm-%E8%B0%83%E5%8F%82%E8%BF%87%E7%A8%8B"><span class="toc-number">3.2.</span> <span class="toc-text">SVM 调参过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#rf-%E8%B0%83%E5%8F%82%E8%BF%87%E7%A8%8B"><span class="toc-number">3.3.</span> <span class="toc-text">RF 调参过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#dt-%E8%B0%83%E5%8F%82%E8%BF%87%E7%A8%8B"><span class="toc-number">3.4.</span> <span class="toc-text">DT 调参过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%9B%E9%80%89%E5%9C%A8dt%E7%AE%97%E6%B3%95%E4%B8%AD%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E7%B3%BB%E6%95%B0%E5%89%8D20%E4%B8%AA%E6%8C%87%E6%A0%87"><span class="toc-number">3.4.1.</span> <span class="toc-text">筛选在DT算法中特征重要性系数前20个指标</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#xgboost-%E8%B0%83%E5%8F%82%E8%BF%87%E7%A8%8B"><span class="toc-number">3.5.</span> <span class="toc-text">XGBoost 调参过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%9B%E9%80%89%E5%9C%A8xgboost%E7%AE%97%E6%B3%95%E4%B8%AD%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E7%B3%BB%E6%95%B0%E5%89%8D20%E4%B8%AA%E6%8C%87%E6%A0%87"><span class="toc-number">3.5.1.</span> <span class="toc-text">筛选在XGBoost算法中特征重要性系数前20个指标</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#gbm-%E8%B0%83%E5%8F%82%E8%BF%87%E7%A8%8B"><span class="toc-number">3.6.</span> <span class="toc-text">GBM 调参过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%9B%E9%80%89%E5%9C%A8gbm%E7%AE%97%E6%B3%95%E4%B8%AD%E7%89%B9%E5%BE%81%E9%87%8D%E8%A6%81%E6%80%A7%E7%B3%BB%E6%95%B0%E5%89%8D20%E4%B8%AA%E6%8C%87%E6%A0%87"><span class="toc-number">3.6.1.</span> <span class="toc-text">筛选在GBM算法中特征重要性系数前20个指标</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/c17bc522.html" title="帕累托图"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/%E4%B8%8D%E6%AD%A2%E5%BD%93%E4%B8%8B.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="帕累托图"></a><div class="content"><a class="title" href="/posts/c17bc522.html" title="帕累托图">帕累托图</a><time datetime="2024-02-13T12:24:11.000Z" title="发表于 2024-02-13 20:24:11">2024-02-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/25edbaed.html" title="条形图正负不同色加表格"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/r3.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="条形图正负不同色加表格"></a><div class="content"><a class="title" href="/posts/25edbaed.html" title="条形图正负不同色加表格">条形图正负不同色加表格</a><time datetime="2024-01-20T14:12:51.000Z" title="发表于 2024-01-20 22:12:51">2024-01-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/e7cf047a.html" title="Python——写入excel"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/248307.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Python——写入excel"></a><div class="content"><a class="title" href="/posts/e7cf047a.html" title="Python——写入excel">Python——写入excel</a><time datetime="2024-01-14T09:43:00.000Z" title="发表于 2024-01-14 17:43:00">2024-01-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/b382cbf3.html" title="Python——word文档"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/r1.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Python——word文档"></a><div class="content"><a class="title" href="/posts/b382cbf3.html" title="Python——word文档">Python——word文档</a><time datetime="2023-10-29T14:10:00.000Z" title="发表于 2023-10-29 22:10:00">2023-10-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/d71a040e.html" title="添加表格"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/pageimg/plttable.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="添加表格"></a><div class="content"><a class="title" href="/posts/d71a040e.html" title="添加表格">添加表格</a><time datetime="2023-09-29T09:42:51.000Z" title="发表于 2023-09-29 17:42:51">2023-09-29</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer_deal"><a class="deal_link" target="_blank" rel="noopener" href="https://weibo.com" title="微博"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://github.com/Rshimmering" title="Github"><i class="anzhiyufont anzhiyu-icon-github"></i></a><img class="footer_mini_logo" title="返回顶部" onclick="anzhiyu.scrollToDest(0,500)" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/t.jpg" size="50px"><a class="deal_link" target="_blank" rel="noopener" href="https://space.bilibili.com" title="Bilibili"><i class="anzhiyufont anzhiyu-icon-bilibili"></i></a><a class="deal_link" target="_blank" rel="noopener" href="https://v.douyin.com/DwCpMEy/" title="抖音"><i class="anzhiyufont anzhiyu-icon-tiktok"></i></a></div><div class="copyright">&copy;2023 - 2024 By Rshimmer</div><div id="workboard"><img class="workSituationImg boardsign" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/work.png" alt="摸鱼~" title="摸鱼~"><div id="runtimeTextTip"></div></div><div class="footer_custom_text">生活的理想就是为了理想的生活</div></div></footer></div></div></div><div id="sidebar"><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/t.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">59</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">33</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">10</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span>🐼文章</span></a><ul class="menus_item_child" style="left:-79px"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size:.9em"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size:.9em"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size:.9em"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span>🥕我的</span></a><ul class="menus_item_child" style="left:-31px"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size:.9em"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size:.9em"></i><span> 百宝箱</span></a></li></ul></div><div class="menus_item"><a class="site-page faa-parent animated-hover" href="javascript:void(0);"><span>🌳关于</span></a><ul class="menus_item_child" style="left:-79px"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size:.9em"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size:.9em"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size:.9em"></i><span> 随便逛逛</span></a></li></ul></div></div></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="9101729293" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size:1rem"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://music.163.com/#/my/m/music/playlist?id=9101729293&quot;, &quot;_blank&quot;);" style="display:none"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.14/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.3.1/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.cbd.int/pangu@5.0.14/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("06/01/2023 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2023 By 安知鱼 V1.5.3",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#3b70fc",
      "",
      "color:#3b70fc",
      "color:#3b70fc",
      "",
      "color:#3b70fc",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 Rshimmer 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script async>(function () {
  var grt = new Date("06/01/2023 00:00:00"); //设置网站上线时间
  var now = new Date();
  var dnum;
  var hnum;
  var mnum;
  var snum;
  var nowHour;

  // 计算并更新天数、小时数、分钟数和秒数
  function updateTime() {
    now = new Date(); // 更新 now 的值
    nowHour = now.getHours(); // 更新 nowHour 的值
    var days = (now - grt) / 1000 / 60 / 60 / 24;
    dnum = Math.floor(days);
    var hours = (now - grt) / 1000 / 60 / 60 - 24 * dnum;
    hnum = Math.floor(hours);
    if (String(hnum).length == 1) {
      hnum = "0" + hnum;
    }
    var minutes = (now - grt) / 1000 / 60 - 24 * 60 * dnum - 60 * hnum;
    mnum = Math.floor(minutes);
    if (String(mnum).length == 1) {
      mnum = "0" + mnum;
    }
    var seconds = (now - grt) / 1000 - 24 * 60 * 60 * dnum - 60 * 60 * hnum - 60 * mnum;
    snum = Math.round(seconds);
    if (String(snum).length == 1) {
      snum = "0" + snum;
    }
  }

  // 更新网页中显示的网站运行时间
  function updateHtml() {
    const footer = document.getElementById("footer");
    if (!footer) return
    let currentTimeHtml = "";
    if (nowHour < 18 && nowHour >= 9) {
      // 如果是上班时间，默认就是"安知鱼-上班摸鱼中.svg"图片，不需要更改
      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    } else {
      // 如果是下班时间，插入"安知鱼-下班啦.svg"图片
      let img = document.querySelector("#workboard .workSituationImg");
      img.src = "/img/bei.png";
      img.title = "下班了就该开开心心的玩耍，嘿嘿~";
      img.alt = "下班了就该开开心心的玩耍，嘿嘿~";

      currentTimeHtml = `本站居然运行了 ${dnum} 天<span id='runtime'> ${hnum} 小时 ${mnum} 分 ${snum} 秒 </span><i class='anzhiyufont anzhiyu-icon-heartbeat' style='color:red'></i>`;
    }

    if (document.getElementById("runtimeTextTip")) {
      document.getElementById("runtimeTextTip").innerHTML = currentTimeHtml;
    }
  }

  setInterval(() => {
    updateTime();
    updateHtml();
  }, 1000);
})();</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><input type="hidden" name="page-type" id="page-type" value="post"></div><script async data-pjax src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.1/bubble/bubble.js"></script><script>var visitorMail="visitor@anheyu.com"</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><script>// 初始化函数
let rm = {};

//禁止图片与超链接拖拽
let aElements = document.getElementsByTagName("a");
for (let i = 0; i < aElements.length; i++) {
  aElements[i].setAttribute("draggable", "false");
  let imgElements = aElements[i].getElementsByTagName("img");
  for (let j = 0; j < imgElements.length; j++) {
    imgElements[j].setAttribute("draggable", "false");
  }
}

// 显示菜单
rm.showRightMenu = function (isTrue, x = 0, y = 0) {
  console.info(x, y)
  let rightMenu = document.getElementById("rightMenu");
  rightMenu.style.top = x + "px";
  rightMenu.style.left = y + "px";
  if (isTrue) {
    rightMenu.style.display = "block";
    stopMaskScroll();
  } else {
    rightMenu.style.display = "none";
  }
};

// 隐藏菜单
rm.hideRightMenu = function () {
  rm.showRightMenu(false);
  let rightMenuMask = document.querySelector("#rightmenu-mask");
  rightMenuMask.style.display = "none";
};

// 尺寸
let rmWidth = document.getElementById("rightMenu").offsetWidth;
let rmHeight = document.getElementById("rightMenu").offsetHeight;

// 重新定义尺寸
rm.reloadrmSize = function () {
  rightMenu.style.visibility = "hidden";
  rightMenu.style.display = "block";
  // 获取宽度和高度
  rmWidth = document.getElementById("rightMenu").offsetWidth;
  rmHeight = document.getElementById("rightMenu").offsetHeight;
  rightMenu.style.visibility = "visible";
};

// 获取点击的href
let domhref = "";
let domImgSrc = "";
let globalEvent = null;

var oncontextmenuFunction = function (event) {
  if (document.body.clientWidth > 768) {
    let pageX = event.clientX + 10; //加10是为了防止显示时鼠标遮在菜单上
    let pageY = event.clientY;

    //其他额外菜单
    const $rightMenuOther = document.querySelector(".rightMenuOther");
    const $rightMenuPlugin = document.querySelector(".rightMenuPlugin");
    const $rightMenuCopyText = document.querySelector("#menu-copytext");
    const $rightMenuPasteText = document.querySelector("#menu-pastetext");
    const $rightMenuCommentText = document.querySelector("#menu-commenttext");
    const $rightMenuNewWindow = document.querySelector("#menu-newwindow");
    const $rightMenuNewWindowImg = document.querySelector("#menu-newwindowimg");
    const $rightMenuCopyLink = document.querySelector("#menu-copylink");
    const $rightMenuCopyImg = document.querySelector("#menu-copyimg");
    const $rightMenuDownloadImg = document.querySelector("#menu-downloadimg");
    const $rightMenuSearch = document.querySelector("#menu-search");
    const $rightMenuSearchBaidu = document.querySelector("#menu-searchBaidu");
    const $rightMenuMusicToggle = document.querySelector("#menu-music-toggle");
    const $rightMenuMusicBack = document.querySelector("#menu-music-back");
    const $rightMenuMusicForward = document.querySelector("#menu-music-forward");
    const $rightMenuMusicPlaylist = document.querySelector("#menu-music-playlist");
    const $rightMenuMusicCopyMusicName = document.querySelector("#menu-music-copyMusicName");

    let href = event.target.href;
    let imgsrc = event.target.currentSrc;

    // 判断模式 扩展模式为有事件
    let pluginMode = false;
    $rightMenuOther.style.display = "block";
    globalEvent = event;

    // 检查是否需要复制 是否有选中文本
    if (selectTextNow && window.getSelection()) {
      pluginMode = true;
      $rightMenuCopyText.style.display = "block";
      $rightMenuCommentText.style.display = "block";
      $rightMenuSearch.style.display = "block";
      $rightMenuSearchBaidu.style.display = "block";
    } else {
      $rightMenuCopyText.style.display = "none";
      $rightMenuCommentText.style.display = "none";
      $rightMenuSearchBaidu.style.display = "none";
      $rightMenuSearch.style.display = "none";
    }

    //检查是否右键点击了链接a标签
    if (href) {
      pluginMode = true;
      $rightMenuNewWindow.style.display = "block";
      $rightMenuCopyLink.style.display = "block";
      domhref = href;
    } else {
      $rightMenuNewWindow.style.display = "none";
      $rightMenuCopyLink.style.display = "none";
    }

    //检查是否需要复制图片
    if (imgsrc) {
      pluginMode = true;
      $rightMenuCopyImg.style.display = "block";
      $rightMenuDownloadImg.style.display = "block";
      $rightMenuNewWindowImg.style.display = "block";
      document.getElementById("rightMenu").style.width="12rem"
      domImgSrc = imgsrc;
    } else {
      $rightMenuCopyImg.style.display = "none";
      $rightMenuDownloadImg.style.display = "none";
      $rightMenuNewWindowImg.style.display = "none";
    }

    // 判断是否为输入框
    if (event.target.tagName.toLowerCase() === "input" || event.target.tagName.toLowerCase() === "textarea") {
      pluginMode = true;
      $rightMenuPasteText.style.display = "block";
    } else {
      $rightMenuPasteText.style.display = "none";
    }
    const navMusicEl = document.querySelector("#nav-music");
    //判断是否是音乐
    if (navMusicEl && navMusicEl.contains(event.target)) {
      pluginMode = true;
      $rightMenuMusicToggle.style.display = "block";
      $rightMenuMusicBack.style.display = "block";
      $rightMenuMusicForward.style.display = "block";
      $rightMenuMusicPlaylist.style.display = "block";
      $rightMenuMusicCopyMusicName.style.display = "block";
    } else {
      $rightMenuMusicToggle.style.display = "none";
      $rightMenuMusicBack.style.display = "none";
      $rightMenuMusicForward.style.display = "none";
      $rightMenuMusicPlaylist.style.display = "none";
      $rightMenuMusicCopyMusicName.style.display = "none";
    }

    // 如果不是扩展模式则隐藏扩展模块
    if (pluginMode) {
      $rightMenuOther.style.display = "none";
      $rightMenuPlugin.style.display = "block";
    } else {
      $rightMenuPlugin.style.display = "none";
    }

    rm.reloadrmSize();

    // 鼠标默认显示在鼠标右下方，当鼠标靠右或靠下时，将菜单显示在鼠标左方\上方
    if (pageX + rmWidth > window.innerWidth) {
      pageX -= rmWidth + 10;
    }
    if (pageY + rmHeight > window.innerHeight) {
      pageY -= pageY + rmHeight - window.innerHeight;
    }

    rm.showRightMenu(true, pageY, pageX);
    document.getElementById("rightmenu-mask").style.display = "flex";
    return false;
  }
};

// 监听右键初始化
window.oncontextmenu = oncontextmenuFunction

// 下载图片状态
rm.downloadimging = false;

// 复制图片到剪贴板
rm.writeClipImg = function (imgsrc) {
  console.log("按下复制");
  rm.hideRightMenu();
  anzhiyu.snackbarShow("正在下载中，请稍后", false, 10000);
  if (rm.downloadimging == false) {
    rm.downloadimging = true;
    setTimeout(function () {
      copyImage(imgsrc);
      anzhiyu.snackbarShow("复制成功！图片已添加盲水印，请遵守版权协议");
      rm.downloadimging = false;
    }, "10000");
  }
};

function imageToBlob(imageURL) {
  const img = new Image();
  const c = document.createElement("canvas");
  const ctx = c.getContext("2d");
  img.crossOrigin = "";
  img.src = imageURL;
  return new Promise(resolve => {
    img.onload = function () {
      c.width = this.naturalWidth;
      c.height = this.naturalHeight;
      ctx.drawImage(this, 0, 0);
      c.toBlob(
        blob => {
          // here the image is a blob
          resolve(blob);
        },
        "image/png",
        0.75
      );
    };
  });
}

async function copyImage(imageURL) {
  const blob = await imageToBlob(imageURL);
  const item = new ClipboardItem({ "image/png": blob });
  navigator.clipboard.write([item]);
}

rm.copyUrl = function (id) {
  const input = document.createElement("input"); // Create a new <input> element
  input.id = "copyVal"; // Set the id of the new element to "copyVal"
  document.body.appendChild(input); // Append the new element to the end of the <body> element
  
  const text = id;
  input.value = text;
  input.select();
  input.setSelectionRange(0, input.value.length);
  document.execCommand("copy");
  
  input.remove(); // Remove the <input> element from the DOM
};

function stopMaskScroll() {
  if (document.getElementById("rightmenu-mask")) {
    let xscroll = document.getElementById("rightmenu-mask");
    xscroll.addEventListener(
      "mousewheel",
      function (e) {
        //阻止浏览器默认方法
        rm.hideRightMenu();
        // e.preventDefault();
      },
      { passive: true }
    );
  }
  if (document.getElementById("rightMenu")) {
    let xscroll = document.getElementById("rightMenu");
    xscroll.addEventListener(
      "mousewheel",
      function (e) {
        //阻止浏览器默认方法
        rm.hideRightMenu();
        // e.preventDefault();
      },
      { passive: true }
    );
  }
}

rm.rightmenuCopyText = function (txt) {
  if (navigator.clipboard) {
    navigator.clipboard.writeText(txt);
  }
  rm.hideRightMenu();
};

rm.copyPageUrl = function (url) {
  if (!url) {
    url = window.location.href;
  }
  rm.copyUrl(url);
  anzhiyu.snackbarShow("复制链接地址成功", false, 2000);
  rm.hideRightMenu();
};

rm.sharePage = function () {
  var content = window.location.href;
  rm.copyUrl(url);
  anzhiyu.snackbarShow("复制链接地址成功", false, 2000);
  rm.hideRightMenu();
};

// 复制当前选中文本
var selectTextNow = "";
document.onmouseup = document.ondblclick = selceText;

function selceText() {
  var txt;
  if (document.selection) {
    txt = document.selection.createRange().text;
  } else {
    txt = window.getSelection().toString();
  }
  selectTextNow = txt !== "" ? txt : "";
}

// 读取剪切板
rm.readClipboard = function () {
  if (navigator.clipboard) {
    navigator.clipboard.readText().then(clipText => rm.insertAtCaret(globalEvent.target, clipText));
  }
};

// 粘贴文本到焦点
rm.insertAtCaret = function (elemt, value) {
  const startPos = elemt.selectionStart,
    endPos = elemt.selectionEnd;
  if (document.selection) {
    elemt.focus();
    var sel = document.selection.createRange();
    sel.text = value;
    elemt.focus();
  } else {
    if (startPos || startPos == "0") {
      var scrollTop = elemt.scrollTop;
      elemt.value = elemt.value.substring(0, startPos) + value + elemt.value.substring(endPos, elemt.value.length);
      elemt.focus();
      elemt.selectionStart = startPos + value.length;
      elemt.selectionEnd = startPos + value.length;
      elemt.scrollTop = scrollTop;
    } else {
      elemt.value += value;
      elemt.focus();
    }
  }
};

//粘贴文本
rm.pasteText = function () {
  const result = rm.readClipboard() || "";
  rm.hideRightMenu();
};

//引用到评论
rm.rightMenuCommentText = function (txt) {
  rm.hideRightMenu();
  const postCommentDom = document.getElementById("post-comment");
  var domTop = postCommentDom.offsetTop;
  window.scrollTo(0, domTop - 80);
  if (txt == "undefined" || txt == "null") txt = "好棒！";
  function setText() {
    setTimeout(() => {
      var input = document.getElementsByClassName("el-textarea__inner")[0];
      if (!input) setText();
      let evt = document.createEvent("HTMLEvents");
      evt.initEvent("input", true, true);
      let inputValue = replaceAll(txt, "\n", "\n> ");
      input.value = "> " + inputValue + "\n\n";
      input.dispatchEvent(evt);
      input.focus();
      input.setSelectionRange(-1, -1);
      if (document.getElementById("comment-tips")) {
        document.getElementById("comment-tips").classList.add("show");
      }
    }, 100);
  }
  setText();
};

//替换所有内容
function replaceAll(string, search, replace) {
  return string.split(search).join(replace);
}

// 百度搜索
rm.searchBaidu = function () {
  anzhiyu.snackbarShow("即将跳转到百度搜索", false, 2000);
  setTimeout(function () {
    window.open("https://www.baidu.com/s?wd=" + selectTextNow);
  }, "2000");
  rm.hideRightMenu();
};

//分享链接
rm.copyLink = function () {
  rm.rightmenuCopyText(domhref);
  anzhiyu.snackbarShow("已复制链接地址");
};

function addRightMenuClickEvent() {
  // 添加点击事件
  document.getElementById("menu-backward").addEventListener("click", function () {
  window.history.back();
    rm.hideRightMenu();
  });

  document.getElementById("menu-forward").addEventListener("click", function () {
    window.history.forward();
    rm.hideRightMenu();
  });

  document.getElementById("menu-refresh").addEventListener("click", function () {
    window.location.reload();
  });

  document.getElementById("menu-top").addEventListener("click", function () {
    anzhiyu.scrollToDest(0, 500);
    rm.hideRightMenu();
  });

  const menuLinks = document.querySelectorAll(".menu-link");
  menuLinks.forEach(function (link) {
    link.addEventListener("click", rm.hideRightMenu);
  });

  document.getElementById("menu-darkmode").addEventListener("click", anzhiyu.switchDarkMode);

  document.getElementById("menu-home") && document.getElementById("menu-home").addEventListener("click", function () {
    window.location.href = window.location.origin;
  });

  document.getElementById("menu-randomPost").addEventListener("click", function () {
    toRandomPost();
  });

  document.getElementById("menu-commentBarrage").addEventListener("click", anzhiyu.switchCommentBarrage);

  document.getElementById("rightmenu-mask").addEventListener("click", rm.hideRightMenu);

  document.getElementById("rightmenu-mask").addEventListener("contextmenu", function (event) {
    rm.hideRightMenu();
    event.preventDefault(); // Prevent the default context menu from appearing
  });

  document.getElementById("menu-copy").addEventListener("click", rm.copyPageUrl);

  document.getElementById("menu-pastetext").addEventListener("click", rm.pasteText);

  document.getElementById("menu-copytext").addEventListener("click", function () {
    rm.rightmenuCopyText(selectTextNow);
    anzhiyu.snackbarShow("复制成功，复制和转载请标注本文地址");
  });

  document.getElementById("menu-commenttext").addEventListener("click", function () {
    rm.rightMenuCommentText(selectTextNow);
  });

  document.getElementById("menu-newwindow").addEventListener("click", function () {
    window.open(domhref, "_blank");
    rm.hideRightMenu();
  });

  document.getElementById("menu-copylink").addEventListener("click", rm.copyLink);

  document.getElementById("menu-downloadimg").addEventListener("click", function () {
    anzhiyu.downloadImage(domImgSrc, "anzhiyu");
  });

  document.getElementById("menu-newwindowimg").addEventListener("click", function () {
    window.open(domImgSrc, "_blank");
    rm.hideRightMenu();
  });

  document.getElementById("menu-copyimg").addEventListener("click", function () {
    rm.writeClipImg(domImgSrc);
  });

  document.getElementById("menu-searchBaidu").addEventListener("click", rm.searchBaidu);

  //音乐
  document.getElementById("menu-music-toggle").addEventListener("click", anzhiyu.musicToggle);

  document.getElementById("menu-music-back").addEventListener("click", anzhiyu.musicSkipBack);

  document.getElementById("menu-music-forward").addEventListener("click", anzhiyu.musicSkipForward);

  document.getElementById("menu-music-copyMusicName").addEventListener("click", function () {
    rm.rightmenuCopyText(anzhiyu.musicGetName());
    anzhiyu.snackbarShow("复制歌曲名称成功", false, 3000);
  });

}

addRightMenuClickEvent();</script><script data-pjax>var themeColorMeta = document.querySelector('meta[name="theme-color"]');
var pageHeaderEl = document.getElementById("page-header");
var navMusicEl = document.getElementById("nav-music");
var consoleEl = document.getElementById("console");
// 已随机的歌曲
var selectRandomSong = [];
// 音乐默认声音大小
var musicVolume = 0.8;
// 是否切换了周杰伦音乐列表
var changeMusicListFlag = false;
// 当前默认播放列表
var defaultPlayMusicList = [];

document.getElementById("page-name").innerText = document.title.split(" | Rshimmer")[0];
anzhiyu.initIndexEssay();
anzhiyu.changeTimeInEssay();
anzhiyu.removeBodyPaceClass();
anzhiyu.qrcodeCreate();
anzhiyu.changeTimeInAlbumDetail();
anzhiyu.reflashEssayWaterFall();
anzhiyu.sayhi();
anzhiyu.stopImgRightDrag();
anzhiyu.addNavBackgroundInit();
anzhiyu.setValueToBodyType();
anzhiyu.catalogActive();
anzhiyu.tagsPageActive();
anzhiyu.categoriesBarActive();
anzhiyu.topCategoriesBarScroll();
anzhiyu.switchRightClickMenuHotReview();
anzhiyu.getCustomPlayList();
anzhiyu.addEventListenerConsoleMusicList(false);
setTimeout(() => {if (typeof addFriendLinksInFooter === "function") {addFriendLinksInFooter();}}, 200)</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload='this.media="all"'><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><script data-pjax>var parent,child;document.getElementById("recent-posts")&&"/"===location.pathname&&(parent=document.getElementById("recent-posts"),child='<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://Rshimmering.github.io/categories/matplotlib/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">⭐ matplotlib (9)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://Rshimmering.github.io/categories/Python操作记录/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🌞 Python操作记录 (19)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://Rshimmering.github.io/categories/数据分析、数据挖掘项目/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🌛 数据分析、数据挖掘项目 (4)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://Rshimmering.github.io/categories/《统计学-第7版》思考题/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 《统计学_第7版》思考题 (14)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="https://Rshimmering.github.io/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>',console.log("已挂载magnet"),parent.insertAdjacentHTML("afterbegin",child))</script><style>#catalog_magnet{flex-wrap:wrap;display:flex;width:100%;justify-content:space-between;padding:10px 10px 0 10px;align-content:flex-start}.magnet_item{flex-basis:calc(50% - 5px);background:#1f4e79;margin-bottom:10px;border-radius:8px;transition:all .2s ease-in-out}.magnet_item:hover{background:#1f4e79}.magnet_link_more{color:#555}.magnet_link{color:#fff}.magnet_link:hover{color:#d2b4de}@media screen and (max-width:600px){.magnet_item{flex-basis:100%}}.magnet_link_context{display:flex;padding:10px;font-size:16px;transition:all .2s ease-in-out}.magnet_link_context:hover{padding:10px 20px}</style><style></style></body></html>